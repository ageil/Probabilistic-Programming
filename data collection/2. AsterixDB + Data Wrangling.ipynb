{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AsterixDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:30:48.648485Z",
     "start_time": "2020-10-22T00:30:48.628733Z"
    }
   },
   "outputs": [],
   "source": [
    "from asterixdb.asterixdb import AsterixConnection\n",
    "from glob import glob\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Asterix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish connection to AsterixDB:\n",
    "\n",
    "(using https://github.com/j-goldsmith/asterixdb-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:30:51.213647Z",
     "start_time": "2020-10-22T00:30:51.203605Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "con = AsterixConnection(server='http://localhost', port=19002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T02:22:05.332820Z",
     "start_time": "2020-10-20T02:22:05.271727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 8,\n",
       "  'alias': 'Nila',\n",
       "  'name': 'NilaMilliron',\n",
       "  'userSince': '2008-01-01T10:10:00.000Z',\n",
       "  'friendIds': [3],\n",
       "  'employment': [{'organizationName': 'Plexlane', 'startDate': '2010-02-28'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = con.query('''\n",
    "#     USE TinySocial;\n",
    "\n",
    "#     SELECT VALUE user\n",
    "#     FROM GleambookUsers user\n",
    "#     WHERE user.id = 8;''')\n",
    "\n",
    "# response.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear dataverse if it already exists(!) and create new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T02:22:15.305677Z",
     "start_time": "2020-10-20T02:22:15.266430Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# response = con.query('''\n",
    "#     DROP DATAVERSE FactMap IF EXISTS;\n",
    "#     CREATE DATAVERSE FactMap;\n",
    "#     ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create subset of only 2019 submissions for experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:32:30.102467Z",
     "start_time": "2020-10-22T00:32:30.098985Z"
    }
   },
   "outputs": [],
   "source": [
    "rt_paths = sorted(glob(\"/Users/ageil/Github/FactMap/Data/reddit/2019/*.json\"))\n",
    "combined = \"\"\n",
    "\n",
    "for p in rt_paths:\n",
    "    combined += 'localhost://' + p + ','\n",
    "    \n",
    "combined = combined[:-1]  # remove last ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:32:30.493059Z",
     "start_time": "2020-10-22T00:32:30.490709Z"
    }
   },
   "outputs": [],
   "source": [
    "q = '''\n",
    "    USE FactMap;\n",
    "    \n",
    "    DROP TYPE submissionTypeTemp IF EXISTS;\n",
    "    CREATE TYPE submissionTypeTemp as {{\n",
    "        uid: uuid\n",
    "    }};\n",
    "    \n",
    "    DROP DATASET PostsTemp IF EXISTS;\n",
    "    CREATE DATASET PostsTemp(submissionTypeTemp)\n",
    "        PRIMARY KEY uid AUTOGENERATED;\n",
    "                \n",
    "    LOAD DATASET PostsTemp\n",
    "    USING localfs ((\"path\"=\"{0}\"),(\"format\"=\"json\"));\n",
    "    '''.format(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T20:37:30.812662Z",
     "start_time": "2020-10-20T20:37:30.807812Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast to intended data format and clean up temp table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T02:26:56.956295Z",
     "start_time": "2020-10-20T02:24:51.837192Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    DROP DATASET posts2019 IF EXISTS;\n",
    "    \n",
    "    CREATE TYPE SubmissionType as {\n",
    "        id: string\n",
    "    };\n",
    "    CREATE DATASET posts2019(SubmissionType)\n",
    "        PRIMARY KEY id;\n",
    "\n",
    "    INSERT INTO posts2019\n",
    "    SELECT \n",
    "    id,\n",
    "    datetime_from_unix_time_in_secs(int(created_utc)) as created_utc,\n",
    "    subreddit_id,\n",
    "    subreddit,\n",
    "    author,\n",
    "    domain,\n",
    "    int(score) as score,\n",
    "    int(num_comments) as num_comments,\n",
    "    title,\n",
    "    url\n",
    "    FROM PostsTemp p;\n",
    "    \n",
    "    DROP DATASET PostsTemp IF EXISTS;\n",
    "    DROP TYPE SubmissionTypeTemp IF EXISTS;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load all reddit submissions with direct load (note BigQuery gives `int` as `string` so have to cast):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:32:44.507981Z",
     "start_time": "2020-10-22T00:32:44.504319Z"
    }
   },
   "outputs": [],
   "source": [
    "rt_paths = sorted(glob(\"/Users/ageil/Github/FactMap/Data/reddit/new/*.json\"))\n",
    "combined = \"\"\n",
    "\n",
    "for p in rt_paths:\n",
    "    combined += 'localhost://' + p + ','\n",
    "    \n",
    "combined = combined[:-1]  # remove last ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T00:32:52.113910Z",
     "start_time": "2020-10-22T00:32:52.109906Z"
    }
   },
   "outputs": [],
   "source": [
    "q = '''\n",
    "    USE FactMap;\n",
    "    \n",
    "    DROP TYPE submissionTypeTemp IF EXISTS;\n",
    "    CREATE TYPE submissionTypeTemp as {{\n",
    "        uid: uuid\n",
    "    }};\n",
    "    \n",
    "    DROP DATASET PostsTemp IF EXISTS;\n",
    "    CREATE DATASET PostsTemp(submissionTypeTemp)\n",
    "        PRIMARY KEY uid AUTOGENERATED;\n",
    "                \n",
    "    LOAD DATASET PostsTemp\n",
    "    USING localfs ((\"path\"=\"{0}\"),(\"format\"=\"json\"));\n",
    "    '''.format(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T22:58:45.087907Z",
     "start_time": "2020-10-20T21:23:26.931351Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cast to intended data format and clean up temp table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T03:48:59.339158Z",
     "start_time": "2020-10-21T03:48:59.283087Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    DROP DATASET posts IF EXISTS;\n",
    "\n",
    "    CREATE DATASET posts(SubmissionType)\n",
    "        PRIMARY KEY id;\n",
    "\n",
    "    UPSERT INTO posts\n",
    "    SELECT \n",
    "        id,\n",
    "        datetime_from_unix_time_in_secs(int(created_utc)) as created_utc,\n",
    "        subreddit_id,\n",
    "        subreddit,\n",
    "        author,\n",
    "        domain,\n",
    "        int(score) as score,\n",
    "        int(num_comments) as num_comments,\n",
    "        title,\n",
    "        url\n",
    "    FROM PostsTemp p;\n",
    "    \n",
    "    DROP DATASET PostsTemp IF EXISTS;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: use `UPSERT INTO` to protect against duplicate ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClaimReview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all claims, generate uid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:43:30.733103Z",
     "start_time": "2020-10-20T12:43:23.030170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    DROP TYPE ReviewsType IF EXISTS;\n",
    "    CREATE TYPE ReviewsType as {\n",
    "        uid: uuid\n",
    "    };\n",
    "    \n",
    "    DROP DATASET claims IF EXISTS;\n",
    "    CREATE DATASET claims(ReviewsType)\n",
    "        PRIMARY KEY uid AUTOGENERATED;\n",
    "                \n",
    "    LOAD DATASET claims\n",
    "    USING localfs ((\"path\"=\"localhost:///Users/ageil/Github/FactMap/Data/claimreviews/claims_2020_combined.json\"),(\"format\"=\"json\"));\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up formatting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:44:15.982093Z",
     "start_time": "2020-10-20T12:44:11.694600Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    CREATE DATASET reviews(ReviewsType)\n",
    "        PRIMARY KEY uid;\n",
    "\n",
    "    INSERT INTO reviews\n",
    "    SELECT \n",
    "        uid,\n",
    "        reviewUrl,\n",
    "        claimReviewed,\n",
    "        countries,\n",
    "        claimReviewed_en,\n",
    "        datetime_from_unix_time_in_secs(claimDate) as claimDate,\n",
    "        datetime_from_unix_time_in_secs(reviewDate) as reviewDate,\n",
    "        reviewAuthor,\n",
    "        reviewRating,\n",
    "        claimAuthor,\n",
    "        tagsRaw,\n",
    "        tagsNamed,\n",
    "        reviewTitle\n",
    "    FROM claims c;\n",
    "    \n",
    "    DROP DATASET claims IF EXISTS;\n",
    "    ''')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save subset with valid/invalid ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:44:22.052542Z",
     "start_time": "2020-10-20T12:44:22.049309Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:44:54.539847Z",
     "start_time": "2020-10-20T12:44:47.698125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64798"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rated = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT r.*\n",
    "    FROM reviews r\n",
    "    WHERE r.reviewRating.bestRating >= r.reviewRating.ratingValue\n",
    "    AND r.reviewRating.ratingValue >= r.reviewRating.worstRating\n",
    "    AND r.reviewRating.bestRating > r.reviewRating.worstRating;\n",
    "''').results\n",
    "\n",
    "with open('/Users/ageil/Github/FactMap/RNN/data/rated_2020.pickle', 'wb') as f:\n",
    "    pickle.dump(rated, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "len(rated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T12:45:11.742995Z",
     "start_time": "2020-10-20T12:45:04.049203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86227"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrated = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT r.*\n",
    "    FROM reviews r\n",
    "    WHERE NOT (r.reviewRating.bestRating >= r.reviewRating.ratingValue\n",
    "    AND r.reviewRating.ratingValue >= r.reviewRating.worstRating\n",
    "    AND r.reviewRating.bestRating > r.reviewRating.worstRating)\n",
    "    OR is_null(r.reviewRating.ratingValue)\n",
    "    OR is_null(r.reviewRating.worstRating)\n",
    "    OR is_null(r.reviewRating.bestRating);\n",
    "''').results\n",
    "\n",
    "with open('/Users/ageil/Github/FactMap/RNN/data/unrated.pickle', 'wb') as f:\n",
    "    pickle.dump(unrated, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "len(unrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors (FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: See vec2json2asterix.py for more efficient pipeline and split original file into 4 using:\n",
    "\n",
    "```\n",
    "split -l 500000 crawl_300d_2M.vec crawl_300d_2M\n",
    "```\n",
    "\n",
    "Then run vec2json.py on the resulting files (in parallel), and use json2asterix.py to push them to the database (in parallel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "USE FactMap;\n",
    "\n",
    "DROP DATASET fasttext IF EXISTS;\n",
    "DROP TYPE EmbeddingType IF EXISTS;\n",
    "\n",
    "CREATE TYPE EmbeddingType AS {\n",
    "    word: string,\n",
    "    vector: [float]\n",
    "};\n",
    "\n",
    "CREATE DATASET fasttext(EmbeddingType)\n",
    "    PRIMARY KEY word;\n",
    "\n",
    "INSERT INTO fasttext\n",
    "    ([\n",
    "        {\"word\": \"hello\", \"vector\": [0.0, 0.1]}\n",
    "    ]);\n",
    "\n",
    "SELECT *\n",
    "FROM fasttext;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Facebook Research's 300-dimensional vectors for 2M words trained on Common Crawl:\n",
    "https://fasttext.cc/docs/en/english-vectors.html\n",
    "\n",
    "Importantly, these were not trained on Wikipedia but on socially 'flawed' words (like our own data)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T05:40:24.897606Z",
     "start_time": "2019-05-05T05:40:24.887786Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = map(float, tokens[1:])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-05T05:57:11.368170Z",
     "start_time": "2019-05-05T05:40:28.778975Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"/Users/anders1991/Github/FactMap/data/fasttext/crawl-300d-2M.vec\"\n",
    "\n",
    "vectors = load_vectors(fname) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-09T06:44:01.616301Z",
     "start_time": "2019-05-09T06:44:00.730988Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    DROP DATASET fasttext IF EXISTS;\n",
    "    DROP TYPE EmbeddingType IF EXISTS;\n",
    "\n",
    "    CREATE TYPE EmbeddingType AS {\n",
    "        word: string,\n",
    "        vector: [float]\n",
    "    };\n",
    "\n",
    "    CREATE DATASET fasttext(EmbeddingType)\n",
    "        PRIMARY KEY word;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert word embeddings into dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T17:24:59.631279Z",
     "start_time": "2019-05-06T17:24:59.603330Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "for w, v in vectors.items():\n",
    "    try:\n",
    "        word = w\n",
    "        vec = *v,\n",
    "        response = con.query('''\n",
    "            USE FactMap;\n",
    "            \n",
    "            INSERT INTO fasttext\n",
    "            ([{{\"word\":\"{0}\", \"vector\":{1}}}])\n",
    "        '''.format(word, list(vec)))\n",
    "    except:\n",
    "        failed.append(w)\n",
    "\n",
    "# print(\"Failed word inserts:\", len(failed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard join (claims = news articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on full fake news source URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-28T22:32:58.846281Z",
     "start_time": "2019-05-28T22:30:42.688161Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SET `compiler.joinmemory` \"128MB\";\n",
    "\n",
    "    DROP DATASET urljoin IF EXISTS;\n",
    "    DROP TYPE PostReviewType IF EXISTS;\n",
    "\n",
    "    CREATE TYPE PostReviewType as {\n",
    "        r: ReviewsType,\n",
    "        p: SubmissionType\n",
    "    };\n",
    "\n",
    "    CREATE DATASET urljoin(PostReviewType)\n",
    "        PRIMARY KEY r.uid, p.id;\n",
    "\n",
    "    INSERT INTO urljoin\n",
    "    SELECT *\n",
    "    FROM posts p, reviews r\n",
    "    WHERE r.claimAuthor.claimURL = p.url;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:24:00.671668Z",
     "start_time": "2020-10-22T13:23:55.082932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 19396\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT u.*\n",
    "    FROM urljoin u;\n",
    "    ''')\n",
    "\n",
    "print('Number of matches:', len(response.results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 14325 pre 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how many unique claimreviews are represented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:24:29.213848Z",
     "start_time": "2020-10-22T13:24:29.109743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique claims: 2623\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT count(distinct r.uid) as c\n",
    "    FROM urljoin u\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "print('Number of unique claims:', response.results[0]['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1652 unique claims are posted across the 14325 reddit submissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many of the ratings are numerically valid/invalid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:24:38.908107Z",
     "start_time": "2020-10-22T13:24:38.809174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique, valid numerical ratings: 1171\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT count(distinct r.uid) as c\n",
    "    FROM urljoin u\n",
    "    WHERE \n",
    "    (r.reviewRating.worstRating < r.reviewRating.bestRating \n",
    "    AND\n",
    "    r.reviewRating.worstRating <= r.reviewRating.ratingValue\n",
    "    AND\n",
    "    r.reviewRating.ratingValue <= r.reviewRating.bestRating)\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "print('Number of unique, valid numerical ratings:', response.results[0]['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 923 pre 2020 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:24:45.817345Z",
     "start_time": "2020-10-22T13:24:45.723643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique, invalid numerical ratings: 1203\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT count(distinct r.uid) as c\n",
    "    FROM urljoin u\n",
    "    WHERE \n",
    "    NOT\n",
    "    (r.reviewRating.worstRating < r.reviewRating.bestRating \n",
    "    AND\n",
    "    r.reviewRating.worstRating <= r.reviewRating.ratingValue\n",
    "    AND\n",
    "    r.reviewRating.ratingValue <= r.reviewRating.bestRating)\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "print('Number of unique, invalid numerical ratings:', response.results[0]['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 723 pre 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard join (review articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:18:38.878227Z",
     "start_time": "2020-10-22T13:54:54.771251Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SET `compiler.joinmemory` \"128MB\";\n",
    "\n",
    "    DROP DATASET facturljoin IF EXISTS;\n",
    "    \n",
    "    CREATE DATASET facturljoin(PostReviewType)\n",
    "        PRIMARY KEY r.uid, p.id;\n",
    "\n",
    "    INSERT INTO facturljoin\n",
    "    SELECT *\n",
    "    FROM posts p, reviews r\n",
    "    WHERE r.reviewUrl = p.url;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:18:45.022693Z",
     "start_time": "2020-10-22T14:18:38.888696Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 27213\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT u.*\n",
    "    FROM facturljoin u;\n",
    "    ''')\n",
    "\n",
    "print('Number of matches:', len(response.results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 19224 pre 2020 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T14:18:45.197971Z",
     "start_time": "2020-10-22T14:18:45.025049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique claims 12918\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT COUNT(DISTINCT r.uid) unique_claims\n",
    "    FROM facturljoin f;\n",
    "    ''')\n",
    "\n",
    "print('Number of unique claims', response.results[0]['unique_claims'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was 8636 pre 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there's actually more corrected news posted to reddit than fake news!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T15:42:20.464666Z",
     "start_time": "2020-10-21T15:42:19.830529Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT COUNT(r.uid) as c, g\n",
    "    FROM facturljoin f\n",
    "    GROUP BY r.uid\n",
    "    GROUP AS g\n",
    "    ORDER BY c desc\n",
    "    LIMIT 5;\n",
    "    ''').results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T15:42:26.236319Z",
     "start_time": "2020-10-21T15:42:26.229606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cross-posts: 36\n",
      "Subreddits:\n",
      " ['politics', 'uspolitics', 'worldpolitics', 'DieOff', 'DieOff', 'redacted', 'LyingTrump', 'moderatepolitics', 'Libertarian', 'Impeach_Trump', 'Laserlike_Hodgepodge', 'topofreddit', 'CringeAnarchy', 'Fuck45', 'worldpolitics', 'worldnews', 'esist', 'gogopgo', 'democrats', 'u_the_foreign_code', 'u_the_economy_club', 'POLITIC', 'TrumptASStic', 'POLITIC', 'u_talesofafallenforest', 'EnoughTrumpSpam', 'POLITIC', 'politics', 'NoShitSherlock', 'POLITIC', 'TrumpTellsTales', 'redacted', 'POLITIC', 'POLITIC', 'chomsky', 'LeftCentral']\n",
      "\n",
      "Number of cross-posts: 36\n",
      "Subreddits:\n",
      " ['politics', 'uspolitics', 'worldpolitics', 'DieOff', 'DieOff', 'redacted', 'LyingTrump', 'moderatepolitics', 'Libertarian', 'Impeach_Trump', 'Laserlike_Hodgepodge', 'topofreddit', 'CringeAnarchy', 'Fuck45', 'worldpolitics', 'worldnews', 'esist', 'gogopgo', 'democrats', 'u_the_foreign_code', 'u_the_economy_club', 'POLITIC', 'TrumptASStic', 'POLITIC', 'u_talesofafallenforest', 'EnoughTrumpSpam', 'POLITIC', 'politics', 'NoShitSherlock', 'POLITIC', 'TrumpTellsTales', 'redacted', 'POLITIC', 'POLITIC', 'chomsky', 'LeftCentral']\n",
      "\n",
      "Number of cross-posts: 32\n",
      "Subreddits:\n",
      " ['LiarLiar', 'The_Donald', 'The_Donald', 'politics', 'politics', 'conspiracy', 'The_Donald', 'EcoInternet', 'politics', 'The_Donald', 'The_Donald', 'The_Donald', 'newjersey', 'Conservative', 'nottheonion', 'politics', 'greatawakening', 'politics', 'The_Donald', 'The_Donald', 'politics', 'POLITIC', 'AnythingGoesPolitics', 'The_Donald', 'politics', 'The_Donald', 'worldnews', 'HRCDiscussion', 'politics', 'Conservative', 'politics', 'WhereAreTheChildren']\n",
      "\n",
      "Number of cross-posts: 31\n",
      "Subreddits:\n",
      " ['The_Donald', 'The_Donald', 'politics', 'The_Donald', 'The_Donald', 'The_Donald', 'The_Donald', 'POLITIC', 'worldpolitics', 'iamatotalpieceofshit', 'SargonofAkkad', 'politics', 'news', 'worldnews', 'ElizabethWarren', 'todayilearned', 'Conservative', 'todayilearned', 'WayOfTheBern', 'QualitySocialism', 'SandersForPresident', 'The_Donald', 'ChapoTrapHouse', 'nottheonion', 'Libertarian', 'BernieSanders', 'trump', 'awfuleverything', 'u_jimmery36', 'OurPresident', 'DeepIntoYouTube']\n",
      "\n",
      "Number of cross-posts: 29\n",
      "Subreddits:\n",
      " ['AHideoKojimaRuse', 'AHideoKojimaRuse', 'gaming', 'gaming', 'metalgearsolid', 'PS4', 'NeverBeGameOver', 'KotakuInAction', 'pcgaming', 'metalgearsolid', 'nottheonion', 'gamernews', 'internettoday', 'TwoBestFriendsPlay', 'VideoGameVanguards', 'Games', 'worldnews', 'nottheonion', 'metalgearsolid', 'giantbomb', 'metalgearsolid', 'nottheonion', 'ChapoTrapHouse', 'nottheonion', 'worldnews', 'TwoBestFriendsPlay', 'inbou_ja', 'nottheonion', 'NonCredibleDefense']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in response:\n",
    "    print(\"Number of cross-posts:\", i['c'])\n",
    "    \n",
    "    subs = [p['f']['p']['subreddit'] for p in i['g']]\n",
    "    print(\"Subreddits:\\n\", subs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On further inspection, there's no need for further fuzzy matching on the review matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard join w/ fuzzy join on Twitter/Wikipedia (claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More refined join, using hard URL join only except for wikipedia and twitter posts, since these URLs to these sites are not claim specific and may refer to multiple tweets/sections.\n",
    "\n",
    "Additional requirements for Twitter/Wikipedia posts include:\n",
    "- The post domain must contain either `wikipedia` or `twitter`.\n",
    "- Minimum caption length is 15 characters (cannot meaningfully distinguish claims below this threshold).\n",
    "- Similar-length claim and post titles must have at least 20% word tokens in common.\n",
    "    - Similar-length is defined as the difference in length between the two titles does not exceed 20% of the shortest title.\n",
    "- Different-length claim and post titles must be contained within one or the other, changing at most 50% of the characters to generate a perfect match to the containing title.\n",
    "    - Different-length is defined as the difference in length between the two titles must be at least 20% of the shortest title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table for fuzzy URL join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:25:00.052026Z",
     "start_time": "2020-10-22T13:24:59.971310Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SET `compiler.joinmemory` \"128MB\";\n",
    "\n",
    "    DROP DATASET fuzzyurljoin IF EXISTS;\n",
    "    \n",
    "    CREATE DATASET fuzzyurljoin(PostReviewType)\n",
    "        PRIMARY KEY r.uid, p.id;\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get URL matches with same-length review and post titles (Jaccard similarity > 20%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:25:03.104117Z",
     "start_time": "2020-10-22T13:25:02.827446Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "        USE FactMap;\n",
    "        \n",
    "        INSERT INTO fuzzyurljoin\n",
    "        SELECT u.*\n",
    "        FROM urljoin u\n",
    "        WHERE\n",
    "            (similarity_jaccard(word_tokens(lower(p.title)), word_tokens(lower(r.claimReviewed))) > 0.20\n",
    "            OR similarity_jaccard(word_tokens(lower(p.title)), word_tokens(lower(r.claimReviewed_en))) > 0.20)\n",
    "            AND (abs(length(r.claimReviewed) - length(p.title)) <= \n",
    "                (array_min([length(r.claimReviewed), length(p.title)])) * 0.2)\n",
    "            AND (array_min([length(r.claimReviewed), length(p.title)]) > 15)\n",
    "            AND (contains(p.domain, \"wikipedia\") OR contains(p.domain, \"twitter\"));\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 227 matches added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 260 matches post 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get URL matches with different-length review and post titles (edit distance > 0.5 * min(review or post title length)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:25:30.855085Z",
     "start_time": "2020-10-22T13:25:28.792100Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    INSERT INTO fuzzyurljoin\n",
    "    SELECT u.*\n",
    "    FROM urljoin u\n",
    "    WHERE\n",
    "            (\n",
    "                (edit_distance_contains(lower(p.title), lower(r.claimReviewed), length(r.claimReviewed) * 0.5)[0] \n",
    "                    OR edit_distance_contains(lower(r.claimReviewed), lower(p.title), length(p.title) * 0.5)[0])\n",
    "                OR\n",
    "                (edit_distance_contains(lower(p.title), lower(r.claimReviewed_en), length(r.claimReviewed_en) * 0.5)[0] \n",
    "                    OR edit_distance_contains(lower(r.claimReviewed_en), lower(p.title), length(p.title) * 0.5)[0])\n",
    "            )\n",
    "            AND (abs(length(r.claimReviewed) - length(p.title)) > \n",
    "                (array_min([length(r.claimReviewed), length(p.title)])) * 0.2)\n",
    "            AND (array_min([length(r.claimReviewed), length(p.title)]) > 15)\n",
    "            AND (contains(p.domain, \"wikipedia\") OR contains(p.domain, \"twitter\"));\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 1166 matches added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 1407 matches added post 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add back in all the other url-joined pairs that are not linked to wikipedia or twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:25:42.435947Z",
     "start_time": "2020-10-22T13:25:41.706579Z"
    }
   },
   "outputs": [],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    INSERT INTO fuzzyurljoin\n",
    "    SELECT u.*\n",
    "    FROM urljoin u\n",
    "    WHERE NOT (contains(p.domain, \"wikipedia\") OR contains(p.domain, \"twitter\"));\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 6809 matches added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "= 10,113 matches added post 2020 update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count total number of (fuzzy) url joined matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:26:21.742783Z",
     "start_time": "2020-10-22T13:26:21.703375Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 12079\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "    \n",
    "    SELECT COUNT(*) as total\n",
    "    FROM fuzzyurljoin u;\n",
    "    ''')\n",
    "\n",
    "print('Number of matches:', response.results[0]['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 14325 matches to 8202. A reduction of 6323 false matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post 2020 update: From 19068 matches to 11780. A reduction of 7288 false matches.\n",
    "\n",
    "Post 2020 full update: From 19396 matches to 12079. A reduction of 7317 false matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:31:44.654050Z",
     "start_time": "2020-10-22T13:31:44.605545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique claims 2289\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT COUNT(DISTINCT r.uid) unique_claims\n",
    "    FROM fuzzyurljoin f;\n",
    "    ''')\n",
    "\n",
    "print('Number of unique claims', response.results[0]['unique_claims'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 1652 unique claims to 1378. A reduction of 274 falsely matched claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post 2020 update: From 2563 unique claims to 2233. A reduction of 330 falsely matched claims."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post 2020 full update: From 2623 unique claims to 2289. A reduction of 334 falsely matched claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:32:44.672636Z",
     "start_time": "2020-10-22T13:32:44.603698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique, valid numerical ratings: 960\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT count(distinct r.uid) as c\n",
    "    FROM fuzzyurljoin u\n",
    "    WHERE \n",
    "    (r.reviewRating.worstRating < r.reviewRating.bestRating \n",
    "    AND\n",
    "    r.reviewRating.worstRating <= r.reviewRating.ratingValue\n",
    "    AND\n",
    "    r.reviewRating.ratingValue <= r.reviewRating.bestRating)\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "print('Number of unique, valid numerical ratings:', response.results[0]['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T13:32:46.899916Z",
     "start_time": "2020-10-22T13:32:46.831146Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique, invalid numerical ratings: 1098\n"
     ]
    }
   ],
   "source": [
    "response = con.query('''\n",
    "    USE FactMap;\n",
    "\n",
    "    SELECT count(distinct r.uid) as c\n",
    "    FROM fuzzyurljoin u\n",
    "    WHERE \n",
    "    NOT\n",
    "    (r.reviewRating.worstRating < r.reviewRating.bestRating \n",
    "    AND\n",
    "    r.reviewRating.worstRating <= r.reviewRating.ratingValue\n",
    "    AND\n",
    "    r.reviewRating.ratingValue <= r.reviewRating.bestRating)\n",
    "    LIMIT 1;\n",
    "    ''')\n",
    "print('Number of unique, invalid numerical ratings:', response.results[0]['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-23T03:35:08.167090Z",
     "start_time": "2019-04-23T03:35:08.045Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# r = con.query('''\n",
    "#     use FactMap;\n",
    "#     SELECT VALUE ds FROM Metadata.`Dataset` ds WHERE DataverseName = 'FactMap';\n",
    "#     SELECT VALUE ds FROM Metadata.`Dataset` ds;\n",
    "#     SELECT VALUE ix FROM Metadata.`Index` ix;''')\n",
    "\n",
    "# r.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
