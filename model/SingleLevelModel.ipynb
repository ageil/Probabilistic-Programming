{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Level Model\n",
    "In our simplest model, we will just model each post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:43:36.606768Z",
     "iopub.status.busy": "2020-11-13T19:43:36.606495Z",
     "iopub.status.idle": "2020-11-13T19:43:37.187873Z",
     "shell.execute_reply": "2020-11-13T19:43:37.187255Z",
     "shell.execute_reply.started": "2020-11-13T19:43:36.606702Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.util import scalar_like\n",
    "from torch.distributions import constraints\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:43:37.189150Z",
     "iopub.status.busy": "2020-11-13T19:43:37.188983Z",
     "iopub.status.idle": "2020-11-13T19:43:37.193776Z",
     "shell.execute_reply": "2020-11-13T19:43:37.193145Z",
     "shell.execute_reply.started": "2020-11-13T19:43:37.189130Z"
    }
   },
   "outputs": [],
   "source": [
    "pyro.enable_validation(__debug__)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the Reddit datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:43:49.586577Z",
     "iopub.status.busy": "2020-11-13T19:43:49.586354Z",
     "iopub.status.idle": "2020-11-13T19:43:50.066277Z",
     "shell.execute_reply": "2020-11-13T19:43:50.065334Z",
     "shell.execute_reply.started": "2020-11-13T19:43:49.586552Z"
    }
   },
   "outputs": [],
   "source": [
    "comments = dict()\n",
    "with open('../data/results/Comments.json') as f:\n",
    "    for line in f:\n",
    "        post = json.loads(line)\n",
    "        comments[post['pid']] = post['api_num_comments'], post['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:43:52.739363Z",
     "iopub.status.busy": "2020-11-13T19:43:52.739178Z",
     "iopub.status.idle": "2020-11-13T19:43:53.261527Z",
     "shell.execute_reply": "2020-11-13T19:43:53.260929Z",
     "shell.execute_reply.started": "2020-11-13T19:43:52.739343Z"
    }
   },
   "outputs": [],
   "source": [
    "corrections = []\n",
    "with open('../data/results/CorrectionPairs.json') as f:\n",
    "    for line in f:\n",
    "        corrections.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:43:53.263079Z",
     "iopub.status.busy": "2020-11-13T19:43:53.262898Z",
     "iopub.status.idle": "2020-11-13T19:43:53.504055Z",
     "shell.execute_reply": "2020-11-13T19:43:53.503309Z",
     "shell.execute_reply.started": "2020-11-13T19:43:53.263063Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('../data/results/NewsPairs.json') as f:\n",
    "    for line in f:\n",
    "        news.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gather relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:44:04.019200Z",
     "iopub.status.busy": "2020-11-13T19:44:04.018986Z",
     "iopub.status.idle": "2020-11-13T19:44:04.027214Z",
     "shell.execute_reply": "2020-11-13T19:44:04.026647Z",
     "shell.execute_reply.started": "2020-11-13T19:44:04.019177Z"
    }
   },
   "outputs": [],
   "source": [
    "def processData(data, items, comments, offset=0):\n",
    "    for idx, n in enumerate(items):\n",
    "        i = idx + offset\n",
    "        isNews = 'isFakeStory' in n['r']['reviewRating']\n",
    "        news_id = n['p']['id']\n",
    "        \n",
    "        num_cmts, cmts = comments[news_id]\n",
    "        c_body_lens = []\n",
    "        c_ups = []\n",
    "        c_downs = []\n",
    "        unique_authors = set()\n",
    "        for c in cmts:\n",
    "            c_body_lens.append(c['body_len'])\n",
    "            c_ups.append(c['ups'])\n",
    "            c_downs.append(c['downs'])\n",
    "            if c['author']:\n",
    "                unique_authors.add(c['author'])\n",
    "\n",
    "            hours = c['delta_seconds'] / 3600.0\n",
    "            if hours <= 0.25:   # cmts in 15 mins\n",
    "                data[i, 7] += 1\n",
    "            if hours <= 0.5:    # cmts in 30 mins\n",
    "                data[i, 8] += 1\n",
    "            if hours <= 1:      # cmts in 1 hour\n",
    "                data[i, 9] += 1\n",
    "            if hours <= 2:      # cmts in 2 hours\n",
    "                data[i, 10] += 1\n",
    "            if hours <= 3:      # cmts in 3 hours\n",
    "                data[i, 11] += 1\n",
    "        \n",
    "        if isNews:\n",
    "            data[i, 0] = 1 if n['r']['reviewRating']['isFakeStory'] else 0\n",
    "        else:\n",
    "            data[i, 0] = 3 if n['r']['reviewRating']['isFakeClaim'] else 2\n",
    "        data[i, 1] = num_cmts\n",
    "        data[i, 2] = np.mean(c_body_lens) if c_body_lens else 0.\n",
    "        data[i, 3] = np.std(c_body_lens) if c_body_lens else 0.\n",
    "        data[i, 4] = np.mean(c_ups) if c_ups else 0.\n",
    "        data[i, 5] = np.std(c_ups) if c_ups else 0.\n",
    "        data[i, 6] = len(unique_authors) if unique_authors else 0.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:44:07.286938Z",
     "iopub.status.busy": "2020-11-13T19:44:07.286718Z",
     "iopub.status.idle": "2020-11-13T19:44:12.115567Z",
     "shell.execute_reply": "2020-11-13T19:44:12.115017Z",
     "shell.execute_reply.started": "2020-11-13T19:44:07.286914Z"
    }
   },
   "outputs": [],
   "source": [
    "num_p_indep = 12\n",
    "data = torch.zeros((len(news) + len(corrections), num_p_indep))\n",
    "\n",
    "data = processData(data, news, comments)\n",
    "data = processData(data, corrections, comments, offset=len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables (in order):\n",
    "\n",
    "0. type\n",
    "1. num_comments\n",
    "2. comment_length_avg\n",
    "3. comment_length_std\n",
    "4. comment_upvotes_avg\n",
    "5. comment_upvotes_std\n",
    "6. num_unique_comment_authors\n",
    "7. num_comments in first 15 mins\n",
    "8. num_comments in first 30 mins\n",
    "9. num_comments in first 1 hour\n",
    "10. num_comments in first 2 hours\n",
    "11. num_comments in first 3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T19:47:24.750343Z",
     "iopub.status.busy": "2020-11-13T19:47:24.750109Z",
     "iopub.status.idle": "2020-11-13T19:47:24.754893Z",
     "shell.execute_reply": "2020-11-13T19:47:24.754311Z",
     "shell.execute_reply.started": "2020-11-13T19:47:24.750317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000, 132.0000, 262.4167, 371.5136,   1.9394,   3.9882,  35.0000,\n",
       "          0.0000,   0.0000,   2.0000,   2.0000,   3.0000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try using non-rectangular data to do the same thing. (Get rid of this type level and make it into a categorical variable instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T18:04:05.643660Z",
     "iopub.status.busy": "2020-11-13T18:04:05.643477Z",
     "iopub.status.idle": "2020-11-13T18:04:05.647816Z",
     "shell.execute_reply": "2020-11-13T18:04:05.647286Z",
     "shell.execute_reply.started": "2020-11-13T18:04:05.643640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   0., 131.],\n",
       "        [  1.,   0.,   0.],\n",
       "        [  1.,   1.,   1.],\n",
       "        ...,\n",
       "        [  1.,   3.,   0.],\n",
       "        [  1.,   3.,   1.],\n",
       "        [  1.,   3.,   6.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T18:05:36.448709Z",
     "iopub.status.busy": "2020-11-13T18:05:36.448494Z",
     "iopub.status.idle": "2020-11-13T18:05:36.455086Z",
     "shell.execute_reply": "2020-11-13T18:05:36.454404Z",
     "shell.execute_reply.started": "2020-11-13T18:05:36.448685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100], [1, 250], [1, 125], [1, 150],\n",
    "                       [1, 50],  [1, 100], [1, 150], [1, 125],\n",
    "                       [1, 20],  [1, 40], [1, 30], [1, 35]])\n",
    "p_data = p_data.transpose(0,1)\n",
    "p_data\n",
    "# dim 0: post-level vars: (bias, commentsFirstHour) \n",
    "# dim 1: obs (post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T18:05:37.775618Z",
     "iopub.status.busy": "2020-11-13T18:05:37.775352Z",
     "iopub.status.idle": "2020-11-13T18:05:37.780186Z",
     "shell.execute_reply": "2020-11-13T18:05:37.779242Z",
     "shell.execute_reply.started": "2020-11-13T18:05:37.775588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100], [1, 250], [1, 125], [1, 150],\n",
    "                       [1, 50],  [1, 100], [1, 150], [1, 125],\n",
    "                       [1, 20],  [1, 40], [1, 30], [1, 35]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-13T18:40:11.808306Z",
     "iopub.status.busy": "2020-11-13T18:40:11.808120Z",
     "iopub.status.idle": "2020-11-13T18:40:11.812387Z",
     "shell.execute_reply": "2020-11-13T18:40:11.811846Z",
     "shell.execute_reply.started": "2020-11-13T18:40:11.808285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500., 1000.,  600.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:59.291123Z",
     "iopub.status.busy": "2020-11-12T02:32:59.290881Z",
     "iopub.status.idle": "2020-11-12T02:32:59.295296Z",
     "shell.execute_reply": "2020-11-12T02:32:59.294343Z",
     "shell.execute_reply.started": "2020-11-12T02:32:59.291098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:00.295494Z",
     "iopub.status.busy": "2020-11-12T02:33:00.295275Z",
     "iopub.status.idle": "2020-11-12T02:33:00.300463Z",
     "shell.execute_reply": "2020-11-12T02:33:00.299861Z",
     "shell.execute_reply.started": "2020-11-12T02:33:00.295471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:01.018688Z",
     "iopub.status.busy": "2020-11-12T02:33:01.018451Z",
     "iopub.status.idle": "2020-11-12T02:33:01.023895Z",
     "shell.execute_reply": "2020-11-12T02:33:01.023048Z",
     "shell.execute_reply.started": "2020-11-12T02:33:01.018662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500.,\n",
       "        1000.,  600.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Post-Level Regression\n",
    "\n",
    "y_p = phi_0 * bias + phi_1 * first_hour_comments + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(p_data, y):\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "        \n",
    "    # define a prior for our regression variables\n",
    "    phi_prior = dist.Normal(torch.zeros((num_p_indeps,1)),\n",
    "                            10. * torch.ones((num_p_indeps,1))) # (num_p_indeps,1)\n",
    "    \n",
    "    phi = pyro.sample(\"phi\", phi_prior)\n",
    "    \n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    with pyro.plate(\"post\", num_posts, dim=-1) as p:\n",
    "        \n",
    "        # indep vars for this post\n",
    "        indeps = p_data[:,p] \n",
    "        \n",
    "        # calculate the mean\n",
    "        mu = torch.matmul(phi.transpose(0,1), indeps)  # (num_p_indeps, 1).T  (num_p_indeps, num_posts)\n",
    "        \n",
    "        # sample\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, 1000.), obs=y[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 3000/3000 [00:45, 66.22it/s, step size=8.63e-01, acc. prob=0.918]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples['phi'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.360312</td>\n",
       "      <td>10.261937</td>\n",
       "      <td>-32.355705</td>\n",
       "      <td>-15.955612</td>\n",
       "      <td>-6.793513</td>\n",
       "      <td>0.230579</td>\n",
       "      <td>7.447685</td>\n",
       "      <td>17.548048</td>\n",
       "      <td>37.224907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.574994</td>\n",
       "      <td>2.344521</td>\n",
       "      <td>2.988956</td>\n",
       "      <td>7.606329</td>\n",
       "      <td>9.967288</td>\n",
       "      <td>11.586669</td>\n",
       "      <td>13.157027</td>\n",
       "      <td>15.470240</td>\n",
       "      <td>19.021179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count       mean        std        min         5%       25%        50%  \\\n",
       "0  2000.0   0.360312  10.261937 -32.355705 -15.955612 -6.793513   0.230579   \n",
       "1  2000.0  11.574994   2.344521   2.988956   7.606329  9.967288  11.586669   \n",
       "\n",
       "         75%        95%        max  \n",
       "0   7.447685  17.548048  37.224907  \n",
       "1  13.157027  15.470240  19.021179  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
