{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Level Model\n",
    "In our simplest model, we will just model each post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:41.846663Z",
     "iopub.status.busy": "2020-11-12T19:23:41.846162Z",
     "iopub.status.idle": "2020-11-12T19:23:42.926519Z",
     "shell.execute_reply": "2020-11-12T19:23:42.926022Z",
     "shell.execute_reply.started": "2020-11-12T19:23:41.846396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.util import scalar_like\n",
    "from torch.distributions import constraints\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:42.927778Z",
     "iopub.status.busy": "2020-11-12T19:23:42.927614Z",
     "iopub.status.idle": "2020-11-12T19:23:42.933909Z",
     "shell.execute_reply": "2020-11-12T19:23:42.933424Z",
     "shell.execute_reply.started": "2020-11-12T19:23:42.927758Z"
    }
   },
   "outputs": [],
   "source": [
    "pyro.enable_validation(__debug__)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the Reddit datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:57.241586Z",
     "iopub.status.busy": "2020-11-12T19:23:57.241369Z",
     "iopub.status.idle": "2020-11-12T19:23:57.758501Z",
     "shell.execute_reply": "2020-11-12T19:23:57.758075Z",
     "shell.execute_reply.started": "2020-11-12T19:23:57.241563Z"
    }
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "with open('../data/results/Comments.json') as f:\n",
    "    for line in f:\n",
    "        comments.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:24:01.634927Z",
     "iopub.status.busy": "2020-11-12T19:24:01.634713Z",
     "iopub.status.idle": "2020-11-12T19:24:02.183535Z",
     "shell.execute_reply": "2020-11-12T19:24:02.182997Z",
     "shell.execute_reply.started": "2020-11-12T19:24:01.634903Z"
    }
   },
   "outputs": [],
   "source": [
    "corrections = []\n",
    "with open('../data/results/CorrectionPairs.json') as f:\n",
    "    for line in f:\n",
    "        corrections.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:24:05.112977Z",
     "iopub.status.busy": "2020-11-12T19:24:05.112755Z",
     "iopub.status.idle": "2020-11-12T19:24:05.374165Z",
     "shell.execute_reply": "2020-11-12T19:24:05.373501Z",
     "shell.execute_reply.started": "2020-11-12T19:24:05.112952Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('../data/results/NewsPairs.json') as f:\n",
    "    for line in f:\n",
    "        news.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gather relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:36.505293Z",
     "iopub.status.busy": "2020-11-12T02:11:36.505076Z",
     "iopub.status.idle": "2020-11-12T02:11:36.516705Z",
     "shell.execute_reply": "2020-11-12T02:11:36.515958Z",
     "shell.execute_reply.started": "2020-11-12T02:11:36.505270Z"
    }
   },
   "outputs": [],
   "source": [
    "news_dict = {}\n",
    "\n",
    "for n in news:\n",
    "    news_id = n['p']['id']\n",
    "    news_num_c = n['p']['num_comments']\n",
    "    news_type = n['r']['reviewRating']['isFakeStory']\n",
    "    news_dict[news_id] = news_type, news_num_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:38.621394Z",
     "iopub.status.busy": "2020-11-12T02:11:38.621129Z",
     "iopub.status.idle": "2020-11-12T02:11:38.647441Z",
     "shell.execute_reply": "2020-11-12T02:11:38.646679Z",
     "shell.execute_reply.started": "2020-11-12T02:11:38.621369Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "\n",
    "for c in corrections:\n",
    "    corr_id = c['p']['id']\n",
    "    corr_num_c = c['p']['num_comments']\n",
    "    corr_type = c['r']['reviewRating']['isFakeClaim']\n",
    "    corr_dict[corr_id] = corr_type, corr_num_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:41.388498Z",
     "iopub.status.busy": "2020-11-12T02:11:41.388259Z",
     "iopub.status.idle": "2020-11-12T02:11:41.703001Z",
     "shell.execute_reply": "2020-11-12T02:11:41.702222Z",
     "shell.execute_reply.started": "2020-11-12T02:11:41.388474Z"
    }
   },
   "outputs": [],
   "source": [
    "p_data = torch.empty((3, len(news_dict) + len(corr_dict)))\n",
    "\n",
    "for i, (isFake, num_comments) in enumerate(news_dict.values()):\n",
    "    p_data[0, i] = 1\n",
    "    p_data[1, i] = 0 if not isFake else 1\n",
    "    p_data[2, i] = num_comments\n",
    "    \n",
    "for i, (isFake, num_comments) in enumerate(corr_dict.values()):\n",
    "    p_data[0, i+len(news_dict)] = 1\n",
    "    p_data[1, i+len(news_dict)] = 2 if not isFake else 3\n",
    "    p_data[2, i+len(news_dict)] = num_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try using non-rectangular data to do the same thing. (Get rid of this type level and make it into a categorical variable instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:57.400959Z",
     "iopub.status.busy": "2020-11-12T02:32:57.400716Z",
     "iopub.status.idle": "2020-11-12T02:32:57.405634Z",
     "shell.execute_reply": "2020-11-12T02:32:57.404960Z",
     "shell.execute_reply.started": "2020-11-12T02:32:57.400935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100], [1, 250], [1, 125], [1, 150],\n",
    "                       [1, 50],  [1, 100], [1, 150], [1, 125],\n",
    "                       [1, 20],  [1, 40], [1, 30], [1, 35]])\n",
    "p_data = p_data.transpose(0,1)\n",
    "# dim 0: post-level vars: (bias, commentsFirstHour) \n",
    "# dim 1: obs (post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500., 1000.,  600.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:59.291123Z",
     "iopub.status.busy": "2020-11-12T02:32:59.290881Z",
     "iopub.status.idle": "2020-11-12T02:32:59.295296Z",
     "shell.execute_reply": "2020-11-12T02:32:59.294343Z",
     "shell.execute_reply.started": "2020-11-12T02:32:59.291098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:00.295494Z",
     "iopub.status.busy": "2020-11-12T02:33:00.295275Z",
     "iopub.status.idle": "2020-11-12T02:33:00.300463Z",
     "shell.execute_reply": "2020-11-12T02:33:00.299861Z",
     "shell.execute_reply.started": "2020-11-12T02:33:00.295471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:01.018688Z",
     "iopub.status.busy": "2020-11-12T02:33:01.018451Z",
     "iopub.status.idle": "2020-11-12T02:33:01.023895Z",
     "shell.execute_reply": "2020-11-12T02:33:01.023048Z",
     "shell.execute_reply.started": "2020-11-12T02:33:01.018662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500.,\n",
       "        1000.,  600.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Post-Level Regression\n",
    "\n",
    "y_p = phi_0 * bias + phi_1 * first_hour_comments + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(p_data, y):\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "        \n",
    "    # define a prior for our regression variables\n",
    "    phi_prior = dist.Normal(torch.zeros((num_p_indeps,1)),\n",
    "                            10. * torch.ones((num_p_indeps,1))) # (num_p_indeps,1)\n",
    "    \n",
    "    phi = pyro.sample(\"phi\", phi_prior)\n",
    "    \n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    with pyro.plate(\"post\", num_posts, dim=-1) as p:\n",
    "        \n",
    "        # indep vars for this post\n",
    "        indeps = p_data[:,p] \n",
    "        \n",
    "        # calculate the mean\n",
    "        mu = torch.matmul(phi.transpose(0,1), indeps)  # (num_p_indeps, 1).T  (num_p_indeps, num_posts)\n",
    "        \n",
    "        # sample\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, 1000.), obs=y[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 3000/3000 [00:45, 66.22it/s, step size=8.63e-01, acc. prob=0.918]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples['phi'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.360312</td>\n",
       "      <td>10.261937</td>\n",
       "      <td>-32.355705</td>\n",
       "      <td>-15.955612</td>\n",
       "      <td>-6.793513</td>\n",
       "      <td>0.230579</td>\n",
       "      <td>7.447685</td>\n",
       "      <td>17.548048</td>\n",
       "      <td>37.224907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.574994</td>\n",
       "      <td>2.344521</td>\n",
       "      <td>2.988956</td>\n",
       "      <td>7.606329</td>\n",
       "      <td>9.967288</td>\n",
       "      <td>11.586669</td>\n",
       "      <td>13.157027</td>\n",
       "      <td>15.470240</td>\n",
       "      <td>19.021179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count       mean        std        min         5%       25%        50%  \\\n",
       "0  2000.0   0.360312  10.261937 -32.355705 -15.955612 -6.793513   0.230579   \n",
       "1  2000.0  11.574994   2.344521   2.988956   7.606329  9.967288  11.586669   \n",
       "\n",
       "         75%        95%        max  \n",
       "0   7.447685  17.548048  37.224907  \n",
       "1  13.157027  15.470240  19.021179  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
