{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Level Model\n",
    "In our simplest model, we will just model each post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:58:16.025514Z",
     "iopub.status.busy": "2020-11-16T19:58:16.025292Z",
     "iopub.status.idle": "2020-11-16T19:58:16.255243Z",
     "shell.execute_reply": "2020-11-16T19:58:16.254553Z",
     "shell.execute_reply.started": "2020-11-16T19:58:16.025490Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:51:05.511950Z",
     "iopub.status.busy": "2020-11-16T19:51:05.511712Z",
     "iopub.status.idle": "2020-11-16T19:51:05.515803Z",
     "shell.execute_reply": "2020-11-16T19:51:05.515197Z",
     "shell.execute_reply.started": "2020-11-16T19:51:05.511924Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pyro\n",
    "# from pyro.infer import MCMC, NUTS\n",
    "# import pyro.distributions as dist\n",
    "# from pyro.distributions.util import scalar_like\n",
    "# from torch.distributions import constraints\n",
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:51:06.139902Z",
     "iopub.status.busy": "2020-11-16T19:51:06.139669Z",
     "iopub.status.idle": "2020-11-16T19:51:06.144031Z",
     "shell.execute_reply": "2020-11-16T19:51:06.143331Z",
     "shell.execute_reply.started": "2020-11-16T19:51:06.139877Z"
    }
   },
   "outputs": [],
   "source": [
    "# pyro.enable_validation(__debug__)\n",
    "# pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the Reddit datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:55:43.945244Z",
     "iopub.status.busy": "2020-11-16T19:55:43.945051Z",
     "iopub.status.idle": "2020-11-16T19:55:44.425539Z",
     "shell.execute_reply": "2020-11-16T19:55:44.425025Z",
     "shell.execute_reply.started": "2020-11-16T19:55:43.945225Z"
    }
   },
   "outputs": [],
   "source": [
    "comments = dict()\n",
    "with open('../data/results/Comments.json') as f:\n",
    "    for line in f:\n",
    "        post = json.loads(line)\n",
    "        comments[post['pid']] = post['api_num_comments'], post['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:55:44.426783Z",
     "iopub.status.busy": "2020-11-16T19:55:44.426621Z",
     "iopub.status.idle": "2020-11-16T19:55:45.001603Z",
     "shell.execute_reply": "2020-11-16T19:55:45.001044Z",
     "shell.execute_reply.started": "2020-11-16T19:55:44.426764Z"
    }
   },
   "outputs": [],
   "source": [
    "corrections = []\n",
    "with open('../data/results/CorrectionPairs.json') as f:\n",
    "    for line in f:\n",
    "        corrections.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:55:45.003270Z",
     "iopub.status.busy": "2020-11-16T19:55:45.003134Z",
     "iopub.status.idle": "2020-11-16T19:55:45.251474Z",
     "shell.execute_reply": "2020-11-16T19:55:45.250716Z",
     "shell.execute_reply.started": "2020-11-16T19:55:45.003254Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('../data/results/NewsPairs.json') as f:\n",
    "    for line in f:\n",
    "        news.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gather relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:55:46.258426Z",
     "iopub.status.busy": "2020-11-16T19:55:46.258209Z",
     "iopub.status.idle": "2020-11-16T19:55:46.267059Z",
     "shell.execute_reply": "2020-11-16T19:55:46.266485Z",
     "shell.execute_reply.started": "2020-11-16T19:55:46.258403Z"
    }
   },
   "outputs": [],
   "source": [
    "def processData(data, items, comments, minutes=60, offset=0):\n",
    "    for idx, n in enumerate(items):\n",
    "        i = idx + offset\n",
    "        \n",
    "        isNews = 'isFakeStory' in n['r']['reviewRating']\n",
    "        news_id = n['p']['id']\n",
    "        \n",
    "        num_cmts, cmts = comments[news_id]\n",
    "        c_body_lens = []\n",
    "        c_ups = []\n",
    "        c_downs = []\n",
    "        unique_authors = set()\n",
    "        for c in cmts:\n",
    "            # skip if comment not created in first _ mins\n",
    "            if c['delta_seconds'] > minutes * 60:\n",
    "                continue\n",
    "\n",
    "            c_minutes = c['delta_seconds'] / 60\n",
    "            if c_minutes <= minutes:   # cmts in first _ mins\n",
    "                data[i, 7] += 1\n",
    "            \n",
    "            c_body_lens.append(c['body_len'])\n",
    "            c_ups.append(c['ups'])\n",
    "            c_downs.append(c['downs'])\n",
    "            \n",
    "            if c['author']:\n",
    "                unique_authors.add(c['author'])\n",
    "\n",
    "        data[i, 0] = num_cmts\n",
    "        if isNews:\n",
    "            data[i, 1] = 1 if n['r']['reviewRating']['isFakeStory'] else 0\n",
    "        else:\n",
    "            data[i, 1] = 3 if n['r']['reviewRating']['isFakeClaim'] else 2\n",
    "        data[i, 2] = np.mean(c_body_lens) if c_body_lens else 0.\n",
    "        data[i, 3] = np.std(c_body_lens) if c_body_lens else 0.\n",
    "        data[i, 4] = np.mean(c_ups) if c_ups else 0.\n",
    "        data[i, 5] = np.std(c_ups) if c_ups else 0.\n",
    "        data[i, 6] = len(unique_authors) if unique_authors else 0.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:58:19.523106Z",
     "iopub.status.busy": "2020-11-16T19:58:19.522916Z",
     "iopub.status.idle": "2020-11-16T19:58:21.268067Z",
     "shell.execute_reply": "2020-11-16T19:58:21.267570Z",
     "shell.execute_reply.started": "2020-11-16T19:58:19.523086Z"
    }
   },
   "outputs": [],
   "source": [
    "num_p_indep = 8\n",
    "data = torch.zeros((len(news) + len(corrections), num_p_indep))\n",
    "\n",
    "data = processData(data, news, comments)\n",
    "data = processData(data, corrections, comments, offset=len(news))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables (in order):\n",
    "\n",
    "0. num_comments\n",
    "1. type\n",
    "2. comment_length_avg\n",
    "3. comment_length_std\n",
    "4. comment_upvotes_avg\n",
    "5. comment_upvotes_std\n",
    "6. num_unique_comment_authors\n",
    "7. num_comments in first _ mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:58:22.979262Z",
     "iopub.status.busy": "2020-11-16T19:58:22.979045Z",
     "iopub.status.idle": "2020-11-16T19:58:22.985138Z",
     "shell.execute_reply": "2020-11-16T19:58:22.984493Z",
     "shell.execute_reply.started": "2020-11-16T19:58:22.979238Z"
    }
   },
   "outputs": [],
   "source": [
    "# select relevant indep vars\n",
    "p_data = data[:, (2,4,6,7)]  # avg cmt length, avg upvotes, num authors\n",
    "t_data = data[:,1].reshape(-1,1)\n",
    "\n",
    "# add bias terms\n",
    "biases = torch.ones_like(t_data)\n",
    "p_data = torch.cat((biases, p_data), dim=1)\n",
    "t_data = torch.cat((biases, t_data), dim=1)\n",
    "\n",
    "# get dep var\n",
    "y = data[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING NUMPYRO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Post-Level Regression\n",
    "\n",
    "y_p = phi_0 * bias + phi_1 * first_hour_comments + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:59:43.648633Z",
     "iopub.status.busy": "2020-11-16T19:59:43.648446Z",
     "iopub.status.idle": "2020-11-16T19:59:43.651409Z",
     "shell.execute_reply": "2020-11-16T19:59:43.650846Z",
     "shell.execute_reply.started": "2020-11-16T19:59:43.648613Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpyro\n",
    "import jax.numpy as jnp\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import numpyro.distributions as dist\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:58:50.289652Z",
     "iopub.status.busy": "2020-11-16T19:58:50.289439Z",
     "iopub.status.idle": "2020-11-16T19:58:50.292819Z",
     "shell.execute_reply": "2020-11-16T19:58:50.292244Z",
     "shell.execute_reply.started": "2020-11-16T19:58:50.289628Z"
    }
   },
   "outputs": [],
   "source": [
    "p_data = np.array(p_data)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T20:01:06.605521Z",
     "iopub.status.busy": "2020-11-16T20:01:06.605302Z",
     "iopub.status.idle": "2020-11-16T20:01:06.610163Z",
     "shell.execute_reply": "2020-11-16T20:01:06.609435Z",
     "shell.execute_reply.started": "2020-11-16T20:01:06.605497Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(p_data, y):\n",
    "    num_posts, num_p_indeps = p_data.shape\n",
    "\n",
    "    # define a prior for our regression variables\n",
    "    phi_prior = dist.Normal(np.zeros((num_p_indeps, 1)),\n",
    "                            10. * np.ones((num_p_indeps, 1)))  # (num_p_indeps, 1)\n",
    "    phi = numpyro.sample(\"phi\", phi_prior)  # (num_p_indeps, 1)\n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    with numpyro.plate(\"post\", num_posts, dim=-1) as p:\n",
    "\n",
    "        # indep vars for this post\n",
    "        indeps = p_data[p,:]  # (num_posts, num_p_indeps)\n",
    "        \n",
    "        # calculate the mean\n",
    "#        mu = torch.matmul(indeps, phi)  # (num_posts, num_p_indeps) (num_p_indeps, 1)\n",
    "        mu = jnp.matmul(indeps, phi)  # (num_posts, num_p_indeps) (num_p_indeps, 1)\n",
    "        \n",
    "        # sample\n",
    "        numpyro.sample(\"obs\", dist.Normal(mu, 1000.), obs=y[p])  # (num_posts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T20:02:14.600427Z",
     "iopub.status.busy": "2020-11-16T20:02:14.600205Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup:   3%|▎         | 84/3000 [32:08<185:29:10, 229.00s/it, 1023 steps of size 4.66e-09. acc. prob=0.67]"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, num_warmup=1000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, p_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-16T18:40:10.379555Z",
     "iopub.status.idle": "2020-11-16T18:40:10.379926Z",
     "shell.execute_reply": "2020-11-16T18:40:10.379777Z"
    }
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "data = az.from_pyro(posterior)\n",
    "az.plot_trace(data, compact=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMPYRO EXPERIMENT END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T19:44:54.877213Z",
     "iopub.status.busy": "2020-11-16T19:44:54.877026Z",
     "iopub.status.idle": "2020-11-16T19:45:03.498858Z",
     "shell.execute_reply": "2020-11-16T19:45:03.497952Z",
     "shell.execute_reply.started": "2020-11-16T19:44:54.877193Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 2000/2000 [00:08, 232.45it/s, step size=9.69e-01, acc. prob=0.895]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      5.0%     95.0%     n_eff     r_hat\n",
      "  phi[0,0]      6.24     10.17      6.00     -9.96     22.84    921.20      1.00\n",
      "  phi[1,0]      9.11      0.69      9.13      7.98     10.20    862.47      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# nuts_kernel = NUTS(model)\n",
    "# mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=1000)\n",
    "# mcmc.run(p_data, y)\n",
    "\n",
    "# print(mcmc.summary())\n",
    "# samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2020-11-16T16:00:31.165428Z",
     "iopub.status.busy": "2020-11-16T16:00:31.165210Z",
     "iopub.status.idle": "2020-11-16T16:00:31.169420Z",
     "shell.execute_reply": "2020-11-16T16:00:31.168833Z",
     "shell.execute_reply.started": "2020-11-16T16:00:31.165403Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2020-11-16T16:00:34.008618Z",
     "iopub.status.busy": "2020-11-16T16:00:34.008395Z",
     "iopub.status.idle": "2020-11-16T16:00:34.033145Z",
     "shell.execute_reply": "2020-11-16T16:00:34.032543Z",
     "shell.execute_reply.started": "2020-11-16T16:00:34.008595Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.047978</td>\n",
       "      <td>9.970550</td>\n",
       "      <td>-30.814848</td>\n",
       "      <td>-16.604683</td>\n",
       "      <td>-6.534851</td>\n",
       "      <td>-0.109931</td>\n",
       "      <td>6.536325</td>\n",
       "      <td>16.897712</td>\n",
       "      <td>34.151043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.473513</td>\n",
       "      <td>2.381326</td>\n",
       "      <td>2.492058</td>\n",
       "      <td>7.646380</td>\n",
       "      <td>9.919976</td>\n",
       "      <td>11.442160</td>\n",
       "      <td>13.075683</td>\n",
       "      <td>15.377494</td>\n",
       "      <td>19.758049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count       mean       std        min         5%       25%        50%  \\\n",
       "0  2000.0   0.047978  9.970550 -30.814848 -16.604683 -6.534851  -0.109931   \n",
       "1  2000.0  11.473513  2.381326   2.492058   7.646380  9.919976  11.442160   \n",
       "\n",
       "         75%        95%        max  \n",
       "0   6.536325  16.897712  34.151043  \n",
       "1  13.075683  15.377494  19.758049  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(posterior_samples['phi'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2020-11-16T16:00:34.008618Z",
     "iopub.status.busy": "2020-11-16T16:00:34.008395Z",
     "iopub.status.idle": "2020-11-16T16:00:34.033145Z",
     "shell.execute_reply": "2020-11-16T16:00:34.032543Z",
     "shell.execute_reply.started": "2020-11-16T16:00:34.008595Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.047978</td>\n",
       "      <td>9.970550</td>\n",
       "      <td>-30.814848</td>\n",
       "      <td>-16.604683</td>\n",
       "      <td>-6.534851</td>\n",
       "      <td>-0.109931</td>\n",
       "      <td>6.536325</td>\n",
       "      <td>16.897712</td>\n",
       "      <td>34.151043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>11.473513</td>\n",
       "      <td>2.381326</td>\n",
       "      <td>2.492058</td>\n",
       "      <td>7.646380</td>\n",
       "      <td>9.919976</td>\n",
       "      <td>11.442160</td>\n",
       "      <td>13.075683</td>\n",
       "      <td>15.377494</td>\n",
       "      <td>19.758049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count       mean       std        min         5%       25%        50%  \\\n",
       "0  2000.0   0.047978  9.970550 -30.814848 -16.604683 -6.534851  -0.109931   \n",
       "1  2000.0  11.473513  2.381326   2.492058   7.646380  9.919976  11.442160   \n",
       "\n",
       "         75%        95%        max  \n",
       "0   6.536325  16.897712  34.151043  \n",
       "1  13.075683  15.377494  19.758049  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
