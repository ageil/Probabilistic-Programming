{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "In our simpler model, we will just model each post as posting about a story coming from one of three groups:\n",
    "- Factual, Disputed Story\n",
    "- Fake, Disputed Story\n",
    "- Corrective Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.util import scalar_like\n",
    "from torch.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.enable_validation(__debug__)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using non-rectangular data to do the same thing. (Get rid of this type level and make it into a categorical variable instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100, 0, 1000], [1, 250, 0, 3000], [1, 125, 0, 1500], [1, 150, 0, 1500],\n",
    "                       [1, 50,  1, 800],  [1, 100, 1, 2500], [1, 150, 1, 1600], [1, 125, 1, 1200],\n",
    "                       [1, 20,  2, 300],  [1, 40,  2,  500], [1, 30,  2, 1000], [1, 35,  2, 600]])\n",
    "p_data = p_data.transpose(0,1)\n",
    "# dim 0: post-level vars: (bias, commentsFirstHour, type, Engagement) \n",
    "# dim 1: obs (post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1],\n",
       "       [ 100,  250,  125,  150,   50,  100,  150,  125,   20,   40,   30,\n",
       "          35],\n",
       "       [   0,    0,    0,    0,    1,    1,    1,    1,    2,    2,    2,\n",
       "           2],\n",
       "       [1000, 3000, 1500, 1500,  800, 2500, 1600, 1200,  300,  500, 1000,\n",
       "         600]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type-Level Data\n",
    "t_data = torch.Tensor([[1], [1], [1]])\n",
    "t_data = t_data.transpose(0,1)\n",
    "# dim 0: type-level vars: (Just bias for now)\n",
    "# dim 1: type (0: Fake, 1: Fact, 2: Corrective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = p_data[-1,:]\n",
    "p_data = p_data[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.],\n",
       "        [  0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,   2.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500.,\n",
       "        1000.,  600.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type-Level Regressions\n",
    "phi_0,t = eta_0^T t_data + epsilon_0\n",
    "phi_1,t = eta_1^T t_data + epsilon_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-Level Regression\n",
    "y_pt = phi_0,t * bias + phi_1,t * first_hour_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(t_data, p_data, y):\n",
    "    num_t_indeps, num_types = t_data.shape\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "    num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "    # construct necessary plates over each level\n",
    "    type_plate = pyro.plate(\"type\", num_types)\n",
    "    post_plate = pyro.plate(\"post\", num_posts)\n",
    "    t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "    p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    # type-level regression variables (shared across all types)\n",
    "    # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "    # each row are the coefficients for a different type-level regression\n",
    "    # eta in proposal\n",
    "    type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "    for pi in p_indep_plate:\n",
    "        for ti in t_indep_plate:\n",
    "            type_level_coefs[pi, ti] = pyro.sample(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(0, 10))\n",
    "        \n",
    "\n",
    "    # Run a type-level regression for the coef on each post-level variable\n",
    "    # phi in proposal\n",
    "    type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,)) # (2,3)\n",
    "    for pi in p_indep_plate:\n",
    "        for t in type_plate:\n",
    "            type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "\n",
    "            # get the restulting type-varying post-level coefficient\n",
    "            type_varying_post_level_coefs[pi,t] = pyro.sample(f\"type_{t}_post_level_coef_{pi}\", \n",
    "                                                              dist.Normal(type_varying_post_level_coef_mu, 10.))\n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    for p in post_plate:\n",
    "        t = int(p_data[-1,p])\n",
    "        \n",
    "        coefs = type_varying_post_level_coefs[:,t] # phi for this post.\n",
    "        indeps = p_data[:-1,p] # indep vars for this post\n",
    "        # calculate the mean\n",
    "        mu = torch.dot(coefs, indeps)\n",
    "        \n",
    "        # sample\n",
    "        pyro.sample(f\"obs_{t}_{p}\", dist.Normal(mu, 1000.), obs=y[p])\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x is a 3D tensor\n",
    "# def guide(t_data, p_data, y):\n",
    "#     num_t_indeps, num_types = t_data.shape\n",
    "#     num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "#     num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "#     # construct necessary plates over each level\n",
    "#     type_plate = pyro.plate(\"type\", num_types)\n",
    "#     post_plate = pyro.plate(\"post\", num_posts)\n",
    "#     t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "#     p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     type_level_coef_locs = torch.empty((num_p_indeps, num_t_indeps,))   # (2,1)\n",
    "#     type_level_coef_scales = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "    \n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coef_locs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_loc\", \n",
    "#                                                       torch.Tensor(0.))\n",
    "#             type_level_coef_scales[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_scale\", \n",
    "#                                                         torch.Tensor(1.), \n",
    "#                                                         constraint=constraints.positive)\n",
    "    \n",
    "#     # type-level regression variables (shared across all types)\n",
    "#     # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "#     type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coefs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(type_level_coef_locs[pi,ti], type_level_coef_scales[pi,ti]))\n",
    "        \n",
    "\n",
    "#     type_varying_post_level_coef_scales = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_scales[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}_scale\", torch.Tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "#     # Run a type-level regression for the coef on each post-level variable\n",
    "#     type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "# #             type_varying_post_level_coef_std = pyro.sample(f\"type_{t}_post_level_coef_{pi}_std\", dist.Uniform(0., 10.))\n",
    "\n",
    "#             # get the restulting type-varying post-level coefficient\n",
    "#             type_varying_post_level_coefs[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}\", dist.Normal(type_varying_post_level_coef_mu, type_varying_post_level_coef_scales[pi,t]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 3000/3000 [04:42, 10.61it/s, step size=4.24e-01, acc. prob=0.917]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(t_data, p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\"Fake\", \"Fact\", \"Corrective\"]\n",
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "#         values = values.reshape((values.shape[0], values.shape[1]))\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "#         site_stats[site_name][\"type\"] = TYPES\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type_level_coef_0_on_pi_0': array([17.530804 ,  5.76418  ,  6.4192877, ..., -7.6067123,  8.856096 ,\n",
       "         3.9015255], dtype=float32),\n",
       " 'type_level_coef_0_on_pi_1': array([ 1.5550346,  5.4955816,  8.0096855, ..., 15.52832  , 10.444261 ,\n",
       "         2.117679 ], dtype=float32),\n",
       " 'type_0_post_level_coef_0': array([ 20.885597 ,  15.160886 ,   8.555441 , ..., -16.150133 ,\n",
       "         27.244688 ,  -7.2345715], dtype=float32),\n",
       " 'type_1_post_level_coef_0': array([  3.3984413,  14.195103 ,  13.916082 , ..., -11.696006 ,\n",
       "         15.135899 ,   8.179921 ], dtype=float32),\n",
       " 'type_2_post_level_coef_0': array([17.12295  , 14.363754 ,  5.2270055, ..., -3.1877165,  6.7148495,\n",
       "         9.67814  ], dtype=float32),\n",
       " 'type_0_post_level_coef_1': array([11.69773  ,  9.559046 ,  8.236295 , ..., 12.13768  , 11.7400465,\n",
       "         4.572459 ], dtype=float32),\n",
       " 'type_1_post_level_coef_1': array([11.235755, 16.03295 ,  8.515057, ..., 10.538765, 22.0059  ,\n",
       "        13.829964], dtype=float32),\n",
       " 'type_2_post_level_coef_1': array([ 5.3343353 ,  0.85543394, 17.319218  , ...,  7.3135557 ,\n",
       "        13.486019  , -0.54460955], dtype=float32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: type_level_coef_0_on_pi_0\n",
      "       mean       std         5%       25%       50%       75%       95%\n",
      "0 -0.253649  10.16328 -17.307125 -6.930449 -0.351429  6.651258  16.59324 \n",
      "\n",
      "Coefficient: type_level_coef_0_on_pi_1\n",
      "       mean       std        5%       25%       50%        75%        95%\n",
      "0  8.990003  5.964278 -0.495992  4.967722  8.942105  13.024718  18.841787 \n",
      "\n",
      "Coefficient: type_0_post_level_coef_0\n",
      "       mean        std         5%        25%       50%      75%        95%\n",
      "0 -0.133035  14.557309 -23.881184 -10.030286 -0.179503  9.68175  24.037552 \n",
      "\n",
      "Coefficient: type_1_post_level_coef_0\n",
      "       mean        std         5%        25%       50%       75%        95%\n",
      "0 -0.131228  14.262767 -22.987999 -10.091269 -0.196285  9.248511  23.524866 \n",
      "\n",
      "Coefficient: type_2_post_level_coef_0\n",
      "      mean        std        5%       25%       50%        75%        95%\n",
      "0  0.28256  14.214364 -23.58259 -8.972426  0.493736  10.041537  23.089745 \n",
      "\n",
      "Coefficient: type_0_post_level_coef_1\n",
      "        mean       std        5%       25%        50%        75%        95%\n",
      "0  11.169072  2.910592  6.609333  9.168008  11.126233  13.116448  15.999722 \n",
      "\n",
      "Coefficient: type_1_post_level_coef_1\n",
      "        mean       std        5%       25%        50%        75%        95%\n",
      "0  12.612781  4.308353  5.492185  9.608792  12.519929  15.607662  19.725157 \n",
      "\n",
      "Coefficient: type_2_post_level_coef_1\n",
      "        mean       std        5%       25%       50%       75%        95%\n",
      "0  11.633686  9.601382 -3.866598  5.119373  11.72336  18.18729  27.162386 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for site, values in summary_types(hmc_samples).items():\n",
    "    print(\"Coefficient: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
