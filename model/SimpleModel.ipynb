{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "In our simpler model, we will just model each post as posting about a story coming from one of three groups:\n",
    "- Factual, Disputed Story\n",
    "- Fake, Disputed Story\n",
    "- Corrective Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.util import scalar_like\n",
    "from torch.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.enable_validation(__debug__)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>CommentsFirstHour</th>\n",
       "      <th>Engagement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fake</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fact</td>\n",
       "      <td>50</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corrective</td>\n",
       "      <td>20</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fake</td>\n",
       "      <td>250</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fact</td>\n",
       "      <td>100</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Corrective</td>\n",
       "      <td>40</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fake</td>\n",
       "      <td>125</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fact</td>\n",
       "      <td>150</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Corrective</td>\n",
       "      <td>30</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type  CommentsFirstHour  Engagement\n",
       "0        Fake                100        1000\n",
       "1        Fact                 50         800\n",
       "2  Corrective                 20         300\n",
       "3        Fake                250        3000\n",
       "4        Fact                100        2500\n",
       "5  Corrective                 40         500\n",
       "6        Fake                125        1500\n",
       "7        Fact                150        1600\n",
       "8  Corrective                 30        1000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"Type\": [\"Fake\", \"Fact\", \"Corrective\", \"Fake\", \"Fact\", \"Corrective\", \"Fake\", \"Fact\", \"Corrective\"],\n",
    "                     \"CommentsFirstHour\": [100, 50, 20, 250, 100, 40, 125, 150, 30],\n",
    "                     \"Engagement\": [1000, 800, 300, 3000, 2500, 500, 1500, 1600, 1000]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor([[[1, 100, 1000], [1, 250, 3000], [1, 125, 1500], [1, 150, 1500]],\n",
    "                     [[1, 50,  800],  [1, 100, 2500], [1, 150, 1600], [1, 125, 1200]],\n",
    "                     [[1, 20,  300],  [1, 40,  500],  [1, 30,  1000], [1, 35, 600]]])\n",
    "data = data.transpose(1,2)\n",
    "# dim 0: Type: (Fake, Fact, Corrective)\n",
    "# dim 1: post-level vars: (bias, commentsFirstHour, Engagement) \n",
    "# dim 2: obs (post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using non-rectangular data to do the same thing. (Get rid of this type level and make it into a categorical variable instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100, 0, 1000], [1, 250, 0, 3000], [1, 125, 0, 1500], [1, 150, 0, 1500],\n",
    "                       [1, 50,  1, 800],  [1, 100, 1, 2500], [1, 150, 1, 1600], [1, 125, 1, 1200],\n",
    "                       [1, 20,  2, 300],  [1, 40,  2,  500], [1, 30,  2, 1000], [1, 35,  2, 600]])\n",
    "p_data = p_data.transpose(0,1)\n",
    "# dim 0: post-level vars: (bias, commentsFirstHour, type, Engagement) \n",
    "# dim 1: obs (post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type-Level Data\n",
    "t_data = torch.Tensor([[1], [1], [1]])\n",
    "t_data = t_data.transpose(0,1)\n",
    "# dim 0: type-level vars: (Just bias for now)\n",
    "# dim 1: type (0: Fake, 1: Fact, 2: Corrective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+02, 2.5000e+02, 1.2500e+02, 1.5000e+02],\n",
       "         [1.0000e+03, 3.0000e+03, 1.5000e+03, 1.5000e+03]],\n",
       "\n",
       "        [[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [5.0000e+01, 1.0000e+02, 1.5000e+02, 1.2500e+02],\n",
       "         [8.0000e+02, 2.5000e+03, 1.6000e+03, 1.2000e+03]],\n",
       "\n",
       "        [[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [2.0000e+01, 4.0000e+01, 3.0000e+01, 3.5000e+01],\n",
       "         [3.0000e+02, 5.0000e+02, 1.0000e+03, 6.0000e+02]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = p_data[-1,:]\n",
    "p_data = p_data[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.],\n",
       "        [  0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,   2.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500.,\n",
       "        1000.,  600.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Sample:  17%|█▋        | 384/2250 [01:11, 15.38it/s, step size=4.98e-01, acc. prob=0.897]"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # x is a 3D tensor\n",
    "# def model(x, y):\n",
    "#     num_types, num_indeps, num_posts = x.shape\n",
    "    \n",
    "#     # construct necessary plates over each level\n",
    "#     type_plate = pyro.plate(\"type\", num_types)\n",
    "#     indep_plate = pyro.plate(\"indep\", num_indeps)\n",
    "#     post_plate = pyro.plate(\"post\", num_posts)\n",
    "\n",
    "#     for t in type_plate:\n",
    "#         type_level_coefs = torch.empty((num_indeps,))\n",
    "#         for i in indep_plate:\n",
    "#             coef = pyro.sample(f\"type_{t}_coef_{i}\", dist.Normal(0, 10)) # sample the type level coefs\n",
    "#             type_level_coefs[i] = coef\n",
    "        \n",
    "#         std = pyro.sample(f\"type_{t}_std\", dist.Uniform(0., 10.)) # sample the y std\n",
    "#         for p in post_plate: # note: currently assumes same number of samples across all types. not always true.\n",
    "#             mu = torch.dot(type_level_coefs, x[t,:,p])\n",
    "#             pyro.sample(f\"obs_{t}_{p}\", dist.Normal(mu, std), obs=y[t,p])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(t_data, p_data, y):\n",
    "    num_t_indeps, num_types = t_data.shape\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "    num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "    # construct necessary plates over each level\n",
    "    type_plate = pyro.plate(\"type\", num_types)\n",
    "    post_plate = pyro.plate(\"post\", num_posts)\n",
    "    t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "    p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    # type-level regression variables (shared across all types)\n",
    "    # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "    type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) \n",
    "    for pi in p_indep_plate:\n",
    "        for ti in t_indep_plate:\n",
    "            type_level_coefs[pi, ti] = pyro.sample(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(0, 10))\n",
    "        \n",
    "\n",
    "    # Run a type-level regression for the coef on each post-level variable\n",
    "    type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,))\n",
    "    for pi in p_indep_plate:\n",
    "        for t in type_plate:\n",
    "            type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "#             type_varying_post_level_coef_std = pyro.sample(f\"type_{t}_post_level_coef_{pi}_std\", dist.Uniform(0., 10.))\n",
    "\n",
    "            # get the restulting type-varying post-level coefficient\n",
    "            type_varying_post_level_coefs[pi,t] = pyro.sample(f\"type_{t}_post_level_coef_{pi}\", dist.Normal(type_varying_post_level_coef_mu, 10.))\n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    for p in post_plate:\n",
    "        t = int(p_data[-1,p])\n",
    "        \n",
    "        coefs = type_varying_post_level_coefs[:,t]\n",
    "        indeps = p_data[:-1,p]\n",
    "        # calculate the mean\n",
    "        mu = torch.dot(coefs, indeps)\n",
    "        \n",
    "        # sample the post-level std\n",
    "#         post_level_std = pyro.sample(f\"post_level_std\", dist.Uniform(0., 10.)) \n",
    "        \n",
    "        # sample\n",
    "        pyro.sample(f\"obs_{t}_{p}\", dist.Normal(mu, 1000.), obs=y[p])\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def guide(t_data, p_data, y):\n",
    "    num_t_indeps, num_types = t_data.shape\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "    num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "    # construct necessary plates over each level\n",
    "    type_plate = pyro.plate(\"type\", num_types)\n",
    "    post_plate = pyro.plate(\"post\", num_posts)\n",
    "    t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "    p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    \n",
    "    type_level_coef_locs = torch.empty((num_p_indeps, num_t_indeps,))\n",
    "    type_level_coef_scales = torch.empty((num_p_indeps, num_t_indeps,))\n",
    "    \n",
    "    for pi in p_indep_plate:\n",
    "        for ti in t_indep_plate:\n",
    "            type_level_coef_locs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_loc\", torch.Tensor(0.))\n",
    "            type_level_coef_scales[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_scale\", torch.Tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "    # type-level regression variables (shared across all types)\n",
    "    # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "    type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) \n",
    "    for pi in p_indep_plate:\n",
    "        for ti in t_indep_plate:\n",
    "            type_level_coefs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(type_level_coef_locs[pi,ti], type_level_coef_scales[pi,ti]))\n",
    "        \n",
    "\n",
    "    type_varying_post_level_coef_scales = torch.empty((num_p_indeps, num_types,))\n",
    "    for pi in p_indep_plate:\n",
    "        for t in type_plate:\n",
    "            type_varying_post_level_coef_scales[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}_scale\", torch.Tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "    # Run a type-level regression for the coef on each post-level variable\n",
    "    type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,))\n",
    "    for pi in p_indep_plate:\n",
    "        for t in type_plate:\n",
    "            type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "#             type_varying_post_level_coef_std = pyro.sample(f\"type_{t}_post_level_coef_{pi}_std\", dist.Uniform(0., 10.))\n",
    "\n",
    "            # get the restulting type-varying post-level coefficient\n",
    "            type_varying_post_level_coefs[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}\", dist.Normal(type_varying_post_level_coef_mu, type_varying_post_level_coef_scales[pi,t]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 3000/3000 [03:51, 12.95it/s, step size=4.24e-01, acc. prob=0.917]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(t_data, p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\"Fake\", \"Fact\", \"Corrective\"]\n",
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "#         values = values.reshape((values.shape[0], values.shape[1]))\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "#         site_stats[site_name][\"type\"] = TYPES\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type_level_coef_0_on_pi_0': array([17.530804 ,  5.76418  ,  6.4192877, ..., -7.6067123,  8.856096 ,\n",
       "         3.9015255], dtype=float32),\n",
       " 'type_level_coef_0_on_pi_1': array([ 1.5550346,  5.4955816,  8.0096855, ..., 15.52832  , 10.444261 ,\n",
       "         2.117679 ], dtype=float32),\n",
       " 'type_0_post_level_coef_0': array([ 20.885597 ,  15.160886 ,   8.555441 , ..., -16.150133 ,\n",
       "         27.244688 ,  -7.2345715], dtype=float32),\n",
       " 'type_1_post_level_coef_0': array([  3.3984413,  14.195103 ,  13.916082 , ..., -11.696006 ,\n",
       "         15.135899 ,   8.179921 ], dtype=float32),\n",
       " 'type_2_post_level_coef_0': array([17.12295  , 14.363754 ,  5.2270055, ..., -3.1877165,  6.7148495,\n",
       "         9.67814  ], dtype=float32),\n",
       " 'type_0_post_level_coef_1': array([11.69773  ,  9.559046 ,  8.236295 , ..., 12.13768  , 11.7400465,\n",
       "         4.572459 ], dtype=float32),\n",
       " 'type_1_post_level_coef_1': array([11.235755, 16.03295 ,  8.515057, ..., 10.538765, 22.0059  ,\n",
       "        13.829964], dtype=float32),\n",
       " 'type_2_post_level_coef_1': array([ 5.3343353 ,  0.85543394, 17.319218  , ...,  7.3135557 ,\n",
       "        13.486019  , -0.54460955], dtype=float32)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: type_level_coef_0_on_pi_0\n",
      "       mean       std         5%       25%       50%       75%       95%\n",
      "0 -0.253649  10.16328 -17.307125 -6.930449 -0.351429  6.651258  16.59324 \n",
      "\n",
      "Coefficient: type_level_coef_0_on_pi_1\n",
      "       mean       std        5%       25%       50%        75%        95%\n",
      "0  8.990003  5.964278 -0.495992  4.967722  8.942105  13.024718  18.841787 \n",
      "\n",
      "Coefficient: type_0_post_level_coef_0\n",
      "       mean        std         5%        25%       50%      75%        95%\n",
      "0 -0.133035  14.557309 -23.881184 -10.030286 -0.179503  9.68175  24.037552 \n",
      "\n",
      "Coefficient: type_1_post_level_coef_0\n",
      "       mean        std         5%        25%       50%       75%        95%\n",
      "0 -0.131228  14.262767 -22.987999 -10.091269 -0.196285  9.248511  23.524866 \n",
      "\n",
      "Coefficient: type_2_post_level_coef_0\n",
      "      mean        std        5%       25%       50%        75%        95%\n",
      "0  0.28256  14.214364 -23.58259 -8.972426  0.493736  10.041537  23.089745 \n",
      "\n",
      "Coefficient: type_0_post_level_coef_1\n",
      "        mean       std        5%       25%        50%        75%        95%\n",
      "0  11.169072  2.910592  6.609333  9.168008  11.126233  13.116448  15.999722 \n",
      "\n",
      "Coefficient: type_1_post_level_coef_1\n",
      "        mean       std        5%       25%        50%        75%        95%\n",
      "0  12.612781  4.308353  5.492185  9.608792  12.519929  15.607662  19.725157 \n",
      "\n",
      "Coefficient: type_2_post_level_coef_1\n",
      "        mean       std        5%       25%       50%       75%        95%\n",
      "0  11.633686  9.601382 -3.866598  5.119373  11.72336  18.18729  27.162386 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for site, values in summary_types(hmc_samples).items():\n",
    "    print(\"Coefficient: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
