{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "In our simpler model, we will just model each post as posting about a story coming from one of three groups:\n",
    "- Factual, Disputed Story\n",
    "- Fake, Disputed Story\n",
    "- Corrective Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have found this to be a useful resource for a hierarchcal model example: https://github.com/pyro-ppl/pyro/blob/dev/examples/baseball.py\n",
    "As well as https://pyro.ai/examples/forecasting_iii.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To start, we will use dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:41.846663Z",
     "iopub.status.busy": "2020-11-12T19:23:41.846162Z",
     "iopub.status.idle": "2020-11-12T19:23:42.926519Z",
     "shell.execute_reply": "2020-11-12T19:23:42.926022Z",
     "shell.execute_reply.started": "2020-11-12T19:23:41.846396Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "from pyro.distributions.util import scalar_like\n",
    "from torch.distributions import constraints\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:42.927778Z",
     "iopub.status.busy": "2020-11-12T19:23:42.927614Z",
     "iopub.status.idle": "2020-11-12T19:23:42.933909Z",
     "shell.execute_reply": "2020-11-12T19:23:42.933424Z",
     "shell.execute_reply.started": "2020-11-12T19:23:42.927758Z"
    }
   },
   "outputs": [],
   "source": [
    "pyro.enable_validation(__debug__)\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the Reddit datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:23:57.241586Z",
     "iopub.status.busy": "2020-11-12T19:23:57.241369Z",
     "iopub.status.idle": "2020-11-12T19:23:57.758501Z",
     "shell.execute_reply": "2020-11-12T19:23:57.758075Z",
     "shell.execute_reply.started": "2020-11-12T19:23:57.241563Z"
    }
   },
   "outputs": [],
   "source": [
    "comments = []\n",
    "with open('../data/results/Comments.json') as f:\n",
    "    for line in f:\n",
    "        comments.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:24:01.634927Z",
     "iopub.status.busy": "2020-11-12T19:24:01.634713Z",
     "iopub.status.idle": "2020-11-12T19:24:02.183535Z",
     "shell.execute_reply": "2020-11-12T19:24:02.182997Z",
     "shell.execute_reply.started": "2020-11-12T19:24:01.634903Z"
    }
   },
   "outputs": [],
   "source": [
    "corrections = []\n",
    "with open('../data/results/CorrectionPairs.json') as f:\n",
    "    for line in f:\n",
    "        corrections.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T19:24:05.112977Z",
     "iopub.status.busy": "2020-11-12T19:24:05.112755Z",
     "iopub.status.idle": "2020-11-12T19:24:05.374165Z",
     "shell.execute_reply": "2020-11-12T19:24:05.373501Z",
     "shell.execute_reply.started": "2020-11-12T19:24:05.112952Z"
    }
   },
   "outputs": [],
   "source": [
    "news = []\n",
    "with open('../data/results/NewsPairs.json') as f:\n",
    "    for line in f:\n",
    "        news.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gather relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:36.505293Z",
     "iopub.status.busy": "2020-11-12T02:11:36.505076Z",
     "iopub.status.idle": "2020-11-12T02:11:36.516705Z",
     "shell.execute_reply": "2020-11-12T02:11:36.515958Z",
     "shell.execute_reply.started": "2020-11-12T02:11:36.505270Z"
    }
   },
   "outputs": [],
   "source": [
    "news_dict = {}\n",
    "\n",
    "for n in news:\n",
    "    news_id = n['p']['id']\n",
    "    news_num_c = n['p']['num_comments']\n",
    "    news_type = n['r']['reviewRating']['isFakeStory']\n",
    "    news_dict[news_id] = news_type, news_num_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:38.621394Z",
     "iopub.status.busy": "2020-11-12T02:11:38.621129Z",
     "iopub.status.idle": "2020-11-12T02:11:38.647441Z",
     "shell.execute_reply": "2020-11-12T02:11:38.646679Z",
     "shell.execute_reply.started": "2020-11-12T02:11:38.621369Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "\n",
    "for c in corrections:\n",
    "    corr_id = c['p']['id']\n",
    "    corr_num_c = c['p']['num_comments']\n",
    "    corr_type = c['r']['reviewRating']['isFakeClaim']\n",
    "    corr_dict[corr_id] = corr_type, corr_num_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:11:41.388498Z",
     "iopub.status.busy": "2020-11-12T02:11:41.388259Z",
     "iopub.status.idle": "2020-11-12T02:11:41.703001Z",
     "shell.execute_reply": "2020-11-12T02:11:41.702222Z",
     "shell.execute_reply.started": "2020-11-12T02:11:41.388474Z"
    }
   },
   "outputs": [],
   "source": [
    "p_data = torch.empty((3, len(news_dict) + len(corr_dict)))\n",
    "\n",
    "for i, (isFake, num_comments) in enumerate(news_dict.values()):\n",
    "    p_data[0, i] = 1\n",
    "    p_data[1, i] = 0 if not isFake else 1\n",
    "    p_data[2, i] = num_comments\n",
    "    \n",
    "for i, (isFake, num_comments) in enumerate(corr_dict.values()):\n",
    "    p_data[0, i+len(news_dict)] = 1\n",
    "    p_data[1, i+len(news_dict)] = 2 if not isFake else 3\n",
    "    p_data[2, i+len(news_dict)] = num_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's try using non-rectangular data to do the same thing. (Get rid of this type level and make it into a categorical variable instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:57.400959Z",
     "iopub.status.busy": "2020-11-12T02:32:57.400716Z",
     "iopub.status.idle": "2020-11-12T02:32:57.405634Z",
     "shell.execute_reply": "2020-11-12T02:32:57.404960Z",
     "shell.execute_reply.started": "2020-11-12T02:32:57.400935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Post-Level Data\n",
    "p_data = torch.Tensor([[1, 100, 0, 1000], [1, 250, 0, 3000], [1, 125, 0, 1500], [1, 150, 0, 1500],\n",
    "                       [1, 50,  1, 800],  [1, 100, 1, 2500], [1, 150, 1, 1600], [1, 125, 1, 1200],\n",
    "                       [1, 20,  2, 300],  [1, 40,  2,  500], [1, 30,  2, 1000], [1, 35,  2, 600]])\n",
    "p_data = p_data.transpose(0,1)\n",
    "# dim 0: post-level vars: (bias, commentsFirstHour, type, Engagement) \n",
    "# dim 1: obs (post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:58.775484Z",
     "iopub.status.busy": "2020-11-12T02:32:58.775251Z",
     "iopub.status.idle": "2020-11-12T02:32:58.778784Z",
     "shell.execute_reply": "2020-11-12T02:32:58.778106Z",
     "shell.execute_reply.started": "2020-11-12T02:32:58.775459Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Type-Level Data\n",
    "t_data = torch.Tensor([[1], [1], [1]])\n",
    "t_data = t_data.transpose(0,1)\n",
    "# dim 0: type-level vars: (Just bias for now)\n",
    "# dim 1: type (0: Fake, 1: Fact, 2: Corrective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:59.079073Z",
     "iopub.status.busy": "2020-11-12T02:32:59.078856Z",
     "iopub.status.idle": "2020-11-12T02:32:59.082749Z",
     "shell.execute_reply": "2020-11-12T02:32:59.081947Z",
     "shell.execute_reply.started": "2020-11-12T02:32:59.079051Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:59.291123Z",
     "iopub.status.busy": "2020-11-12T02:32:59.290881Z",
     "iopub.status.idle": "2020-11-12T02:32:59.295296Z",
     "shell.execute_reply": "2020-11-12T02:32:59.294343Z",
     "shell.execute_reply.started": "2020-11-12T02:32:59.291098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 12])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:32:59.467165Z",
     "iopub.status.busy": "2020-11-12T02:32:59.466896Z",
     "iopub.status.idle": "2020-11-12T02:32:59.471423Z",
     "shell.execute_reply": "2020-11-12T02:32:59.469693Z",
     "shell.execute_reply.started": "2020-11-12T02:32:59.467136Z"
    }
   },
   "outputs": [],
   "source": [
    "y = p_data[-1,:]\n",
    "p_data = p_data[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:00.295494Z",
     "iopub.status.busy": "2020-11-12T02:33:00.295275Z",
     "iopub.status.idle": "2020-11-12T02:33:00.300463Z",
     "shell.execute_reply": "2020-11-12T02:33:00.299861Z",
     "shell.execute_reply.started": "2020-11-12T02:33:00.295471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.],\n",
       "        [100., 250., 125., 150.,  50., 100., 150., 125.,  20.,  40.,  30.,  35.],\n",
       "        [  0.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,   2.,   2.,   2.,   2.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:00.533668Z",
     "iopub.status.busy": "2020-11-12T02:33:00.533409Z",
     "iopub.status.idle": "2020-11-12T02:33:00.538834Z",
     "shell.execute_reply": "2020-11-12T02:33:00.537982Z",
     "shell.execute_reply.started": "2020-11-12T02:33:00.533627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 12])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:01.018688Z",
     "iopub.status.busy": "2020-11-12T02:33:01.018451Z",
     "iopub.status.idle": "2020-11-12T02:33:01.023895Z",
     "shell.execute_reply": "2020-11-12T02:33:01.023048Z",
     "shell.execute_reply.started": "2020-11-12T02:33:01.018662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1000., 3000., 1500., 1500.,  800., 2500., 1600., 1200.,  300.,  500.,\n",
       "        1000.,  600.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Type-Level Regressions\n",
    "\n",
    "phi_0,t = eta_0^T t_data + epsilon_0\n",
    "\n",
    "phi_1,t = eta_1^T t_data + epsilon_1\n",
    "\n",
    "Post-Level Regression\n",
    "\n",
    "y_pt = phi_0,t * bias + phi_1,t * first_hour_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x is a 3D tensor\n",
    "def model(t_data, p_data, y):\n",
    "    num_t_indeps, num_types = t_data.shape\n",
    "    num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "    num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "    # construct necessary plates over each level\n",
    "    type_plate = pyro.plate(\"type\", num_types, dim=-1)\n",
    "    post_plate = pyro.plate(\"post\", num_posts, dim=-1)\n",
    "    t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps, dim=-1)\n",
    "    p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps, dim=-2)\n",
    "    \n",
    "    \n",
    "    # type-level regression variables (shared across all types)\n",
    "    # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "    # each row are the coefficients for a different type-level regression\n",
    "    # eta in proposal\n",
    "    eta = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "    with t_indep_plate as ti:\n",
    "        with p_indep_plate as pi:\n",
    "            eta[pi, ti] = pyro.sample(\"eta\", dist.Normal(torch.zeros_like(eta), 10)).reshape(2)\n",
    "        \n",
    "\n",
    "    # Run a type-level regression for the coef on each post-level variable\n",
    "    # phi in proposal\n",
    "    phi = torch.empty((num_p_indeps, num_types,)) # (2,3)\n",
    "    with type_plate as t:\n",
    "        with p_indep_plate as pi:\n",
    "            phi_mu = torch.matmul(eta[pi,:], t_data[:,t])  # (num_p_indeps, num_t_indeps)   (num_t_indeps, num_types)\n",
    "            # phi_mu = torch.dot(eta[pi,:], t_data[:,t])\n",
    "\n",
    "            # get the restulting type-varying post-level coefficient\n",
    "            phi_prior = dist.Normal(phi_mu, 10. * torch.ones_like(phi_mu))\n",
    "            samp = pyro.sample(\"phi\", phi_prior)\n",
    "            phi = samp\n",
    "    \n",
    "    # for each post, use the correct set of coefficients to run our post-level regression\n",
    "    with post_plate as p:\n",
    "        t = p_data[-1,p].long()\n",
    "        \n",
    "        coefs = phi[:,t] # phi for this post.\n",
    "        indeps = p_data[:-1,p] # indep vars for this post\n",
    "        # calculate the mean\n",
    "        mu = torch.matmul(coefs.T, indeps)  # (num_p_indeps, 1).T  (num_p_indeps, num_posts)\n",
    "        # mu = torch.dot(coefs, indeps)\n",
    "        \n",
    "        # sample\n",
    "        pyro.sample(\"obs\", dist.Normal(mu, 1000.), obs=y[p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # x is a 3D tensor\n",
    "# def guide(t_data, p_data, y):\n",
    "#     num_t_indeps, num_types = t_data.shape\n",
    "#     num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "#     num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "#     # construct necessary plates over each level\n",
    "#     type_plate = pyro.plate(\"type\", num_types)\n",
    "#     post_plate = pyro.plate(\"post\", num_posts)\n",
    "#     t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "#     p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     type_level_coef_locs = torch.empty((num_p_indeps, num_t_indeps,))   # (2,1)\n",
    "#     type_level_coef_scales = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "    \n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coef_locs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_loc\", \n",
    "#                                                       torch.Tensor(0.))\n",
    "#             type_level_coef_scales[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_scale\", \n",
    "#                                                         torch.Tensor(1.), \n",
    "#                                                         constraint=constraints.positive)\n",
    "    \n",
    "#     # type-level regression variables (shared across all types)\n",
    "#     # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "#     type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coefs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(type_level_coef_locs[pi,ti], type_level_coef_scales[pi,ti]))\n",
    "        \n",
    "\n",
    "#     type_varying_post_level_coef_scales = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_scales[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}_scale\", torch.Tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "#     # Run a type-level regression for the coef on each post-level variable\n",
    "#     type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "# #             type_varying_post_level_coef_std = pyro.sample(f\"type_{t}_post_level_coef_{pi}_std\", dist.Uniform(0., 10.))\n",
    "\n",
    "#             # get the restulting type-varying post-level coefficient\n",
    "#             type_varying_post_level_coefs[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}\", dist.Normal(type_varying_post_level_coef_mu, type_varying_post_level_coef_scales[pi,t]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(t_data, p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TYPES = [\"Fake\", \"Fact\", \"Corrective\"]\n",
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "#         values = values.reshape((values.shape[0], values.shape[1]))\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "#         site_stats[site_name][\"type\"] = TYPES\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type-Level Regressions\n",
    "\n",
    "phi_0,t = eta_0^T t_data + epsilon_0\n",
    "\n",
    "phi_1,t = eta_1^T t_data + epsilon_1\n",
    "\n",
    "Post-Level Regression\n",
    "\n",
    "y_pt = phi_0,t * bias + phi_1,t * first_hour_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = pd.DataFrame(hmc_samples['eta'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,0,:])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,1,:])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for site, values in summary_types(hmc_samples).items():\n",
    "    print(\"Coefficient: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:16:14.128797Z",
     "iopub.status.busy": "2020-11-12T03:16:14.128547Z",
     "iopub.status.idle": "2020-11-12T03:16:14.137757Z",
     "shell.execute_reply": "2020-11-12T03:16:14.136825Z",
     "shell.execute_reply.started": "2020-11-12T03:16:14.128771Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T02:33:02.451334Z",
     "iopub.status.busy": "2020-11-12T02:33:02.451028Z",
     "iopub.status.idle": "2020-11-12T02:33:02.455489Z",
     "shell.execute_reply": "2020-11-12T02:33:02.454642Z",
     "shell.execute_reply.started": "2020-11-12T02:33:02.451306Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # x is a 3D tensor\n",
    "# def guide(t_data, p_data, y):\n",
    "#     num_t_indeps, num_types = t_data.shape\n",
    "#     num_p_indeps, num_posts = p_data.shape\n",
    "    \n",
    "#     num_p_indeps -= 1 # The last p_indep is just the type.\n",
    "    \n",
    "#     # construct necessary plates over each level\n",
    "#     type_plate = pyro.plate(\"type\", num_types)\n",
    "#     post_plate = pyro.plate(\"post\", num_posts)\n",
    "#     t_indep_plate = pyro.plate(\"t_indep\", num_t_indeps)\n",
    "#     p_indep_plate = pyro.plate(\"p_indep\", num_p_indeps)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     type_level_coef_locs = torch.empty((num_p_indeps, num_t_indeps,))   # (2,1)\n",
    "#     type_level_coef_scales = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "    \n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coef_locs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_loc\", \n",
    "#                                                       torch.Tensor(0.))\n",
    "#             type_level_coef_scales[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}_scale\", \n",
    "#                                                         torch.Tensor(1.), \n",
    "#                                                         constraint=constraints.positive)\n",
    "    \n",
    "#     # type-level regression variables (shared across all types)\n",
    "#     # one coef for each type-level indep var for each of num_p_indeps type-level regressions\n",
    "#     type_level_coefs = torch.empty((num_p_indeps, num_t_indeps,)) # (2,1)\n",
    "#     for pi in p_indep_plate:\n",
    "#         for ti in t_indep_plate:\n",
    "#             type_level_coefs[pi, ti] = pyro.param(f\"type_level_coef_{ti}_on_pi_{pi}\", dist.Normal(type_level_coef_locs[pi,ti], type_level_coef_scales[pi,ti]))\n",
    "        \n",
    "\n",
    "#     type_varying_post_level_coef_scales = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_scales[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}_scale\", torch.Tensor(1.), constraint=constraints.positive)\n",
    "    \n",
    "#     # Run a type-level regression for the coef on each post-level variable\n",
    "#     type_varying_post_level_coefs = torch.empty((num_p_indeps, num_types,))\n",
    "#     for pi in p_indep_plate:\n",
    "#         for t in type_plate:\n",
    "#             type_varying_post_level_coef_mu = torch.dot(type_level_coefs[pi,:], t_data[:,t])\n",
    "# #             type_varying_post_level_coef_std = pyro.sample(f\"type_{t}_post_level_coef_{pi}_std\", dist.Uniform(0., 10.))\n",
    "\n",
    "#             # get the restulting type-varying post-level coefficient\n",
    "#             type_varying_post_level_coefs[pi,t] = pyro.param(f\"type_{t}_post_level_coef_{pi}\", dist.Normal(type_varying_post_level_coef_mu, type_varying_post_level_coef_scales[pi,t]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:16:15.797480Z",
     "iopub.status.busy": "2020-11-12T03:16:15.797284Z",
     "iopub.status.idle": "2020-11-12T03:17:27.250866Z",
     "shell.execute_reply": "2020-11-12T03:17:27.250225Z",
     "shell.execute_reply.started": "2020-11-12T03:16:15.797460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 3000/3000 [01:11, 41.99it/s, step size=4.60e-01, acc. prob=0.895]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, warmup_steps=1000)\n",
    "mcmc.run(t_data, p_data, y)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:17:30.512487Z",
     "iopub.status.busy": "2020-11-12T03:17:30.512279Z",
     "iopub.status.idle": "2020-11-12T03:17:30.516155Z",
     "shell.execute_reply": "2020-11-12T03:17:30.515611Z",
     "shell.execute_reply.started": "2020-11-12T03:17:30.512467Z"
    }
   },
   "outputs": [],
   "source": [
    "TYPES = [\"Fake\", \"Fact\", \"Corrective\"]\n",
    "# Utility function to print latent sites' quantile information.\n",
    "def summary_types(samples):\n",
    "    site_stats = {}\n",
    "    i = 0\n",
    "    for site_name, values in samples.items():\n",
    "#         values = values.reshape((values.shape[0], values.shape[1]))\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "#         site_stats[site_name][\"type\"] = TYPES\n",
    "        i += 1\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type-Level Regressions\n",
    "\n",
    "phi_0,t = eta_0^T t_data + epsilon_0\n",
    "\n",
    "phi_1,t = eta_1^T t_data + epsilon_1\n",
    "\n",
    "Post-Level Regression\n",
    "\n",
    "y_pt = phi_0,t * bias + phi_1,t * first_hour_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:36:23.700173Z",
     "iopub.status.busy": "2020-11-12T03:36:23.699956Z",
     "iopub.status.idle": "2020-11-12T03:36:23.724920Z",
     "shell.execute_reply": "2020-11-12T03:36:23.724134Z",
     "shell.execute_reply.started": "2020-11-12T03:36:23.700150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.706751</td>\n",
       "      <td>10.270098</td>\n",
       "      <td>-29.916935</td>\n",
       "      <td>-15.337079</td>\n",
       "      <td>-5.248812</td>\n",
       "      <td>1.612831</td>\n",
       "      <td>8.839247</td>\n",
       "      <td>18.441372</td>\n",
       "      <td>37.313736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>9.044466</td>\n",
       "      <td>4.997986</td>\n",
       "      <td>-8.644859</td>\n",
       "      <td>0.661086</td>\n",
       "      <td>5.803686</td>\n",
       "      <td>8.933012</td>\n",
       "      <td>12.146065</td>\n",
       "      <td>17.423727</td>\n",
       "      <td>26.772738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean        std        min         5%       25%       50%  \\\n",
       "0  2000.0  1.706751  10.270098 -29.916935 -15.337079 -5.248812  1.612831   \n",
       "1  2000.0  9.044466   4.997986  -8.644859   0.661086  5.803686  8.933012   \n",
       "\n",
       "         75%        95%        max  \n",
       "0   8.839247  18.441372  37.313736  \n",
       "1  12.146065  17.423727  26.772738  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['eta'][:,:,0])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:35:23.362725Z",
     "iopub.status.busy": "2020-11-12T03:35:23.362486Z",
     "iopub.status.idle": "2020-11-12T03:35:23.391986Z",
     "shell.execute_reply": "2020-11-12T03:35:23.391015Z",
     "shell.execute_reply.started": "2020-11-12T03:35:23.362700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.196438</td>\n",
       "      <td>14.104898</td>\n",
       "      <td>-50.165806</td>\n",
       "      <td>-21.042094</td>\n",
       "      <td>-7.121529</td>\n",
       "      <td>2.229118</td>\n",
       "      <td>11.615298</td>\n",
       "      <td>25.494761</td>\n",
       "      <td>47.577095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.341028</td>\n",
       "      <td>14.508185</td>\n",
       "      <td>-49.305668</td>\n",
       "      <td>-21.621042</td>\n",
       "      <td>-7.537164</td>\n",
       "      <td>2.469201</td>\n",
       "      <td>12.378116</td>\n",
       "      <td>25.953935</td>\n",
       "      <td>51.454567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2.311025</td>\n",
       "      <td>14.554549</td>\n",
       "      <td>-65.808296</td>\n",
       "      <td>-21.430155</td>\n",
       "      <td>-7.208467</td>\n",
       "      <td>2.319745</td>\n",
       "      <td>12.079975</td>\n",
       "      <td>26.343111</td>\n",
       "      <td>48.761379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count      mean        std        min         5%       25%       50%  \\\n",
       "0  2000.0  2.196438  14.104898 -50.165806 -21.042094 -7.121529  2.229118   \n",
       "1  2000.0  2.341028  14.508185 -49.305668 -21.621042 -7.537164  2.469201   \n",
       "2  2000.0  2.311025  14.554549 -65.808296 -21.430155 -7.208467  2.319745   \n",
       "\n",
       "         75%        95%        max  \n",
       "0  11.615298  25.494761  47.577095  \n",
       "1  12.378116  25.953935  51.454567  \n",
       "2  12.079975  26.343111  48.761379  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,0,:])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:35:36.671683Z",
     "iopub.status.busy": "2020-11-12T03:35:36.671436Z",
     "iopub.status.idle": "2020-11-12T03:35:36.696054Z",
     "shell.execute_reply": "2020-11-12T03:35:36.695065Z",
     "shell.execute_reply.started": "2020-11-12T03:35:36.671655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>5%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>95%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.135343</td>\n",
       "      <td>1.202159</td>\n",
       "      <td>7.908581</td>\n",
       "      <td>10.209356</td>\n",
       "      <td>11.277381</td>\n",
       "      <td>12.104874</td>\n",
       "      <td>12.982046</td>\n",
       "      <td>14.066499</td>\n",
       "      <td>15.807629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.133224</td>\n",
       "      <td>1.185028</td>\n",
       "      <td>7.895435</td>\n",
       "      <td>10.183636</td>\n",
       "      <td>11.328020</td>\n",
       "      <td>12.143082</td>\n",
       "      <td>12.947352</td>\n",
       "      <td>14.082853</td>\n",
       "      <td>16.358557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.157056</td>\n",
       "      <td>1.250139</td>\n",
       "      <td>8.331654</td>\n",
       "      <td>10.151919</td>\n",
       "      <td>11.260973</td>\n",
       "      <td>12.143256</td>\n",
       "      <td>12.998227</td>\n",
       "      <td>14.226850</td>\n",
       "      <td>15.994568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count       mean       std       min         5%        25%        50%  \\\n",
       "0  2000.0  12.135343  1.202159  7.908581  10.209356  11.277381  12.104874   \n",
       "1  2000.0  12.133224  1.185028  7.895435  10.183636  11.328020  12.143082   \n",
       "2  2000.0  12.157056  1.250139  8.331654  10.151919  11.260973  12.143256   \n",
       "\n",
       "         75%        95%        max  \n",
       "0  12.982046  14.066499  15.807629  \n",
       "1  12.947352  14.082853  16.358557  \n",
       "2  12.998227  14.226850  15.994568  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.DataFrame(hmc_samples['phi'][:,1,:])\n",
    "m.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:23:00.395892Z",
     "iopub.status.busy": "2020-11-12T03:23:00.395681Z",
     "iopub.status.idle": "2020-11-12T03:23:00.401622Z",
     "shell.execute_reply": "2020-11-12T03:23:00.400920Z",
     "shell.execute_reply.started": "2020-11-12T03:23:00.395871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': array([[[-4.3591666],\n",
       "         [ 8.260902 ]],\n",
       " \n",
       "        [[-5.7180996],\n",
       "         [10.742426 ]],\n",
       " \n",
       "        [[-4.659203 ],\n",
       "         [12.412684 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3.0134025],\n",
       "         [17.954956 ]],\n",
       " \n",
       "        [[-8.488964 ],\n",
       "         [17.422304 ]],\n",
       " \n",
       "        [[ 0.9033203],\n",
       "         [ 1.0316684]]], dtype=float32),\n",
       " 'phi': array([[[  0.20939255,   5.0939555 , -11.443418  ],\n",
       "         [ 10.755408  ,   9.72297   ,  10.885258  ]],\n",
       " \n",
       "        [[ -0.35368305,   1.3452442 , -10.354859  ],\n",
       "         [ 11.450345  ,  10.128931  ,   9.690924  ]],\n",
       " \n",
       "        [[ -1.8811574 ,   2.898465  , -13.184977  ],\n",
       "         [ 11.258858  ,  10.710872  ,  10.185942  ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-12.598831  ,  -8.250435  ,  -3.7482057 ],\n",
       "         [ 11.766134  ,  11.714023  ,  11.396531  ]],\n",
       " \n",
       "        [[ -2.9567347 ,  13.471781  ,   2.5307357 ],\n",
       "         [ 10.347951  ,  12.134154  ,  10.812072  ]],\n",
       " \n",
       "        [[  3.879755  ,  -3.5656176 ,  13.715727  ],\n",
       "         [ 11.789518  ,  12.360553  ,  12.128419  ]]], dtype=float32)}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T03:17:51.640087Z",
     "iopub.status.busy": "2020-11-12T03:17:51.639529Z",
     "iopub.status.idle": "2020-11-12T03:17:51.667197Z",
     "shell.execute_reply": "2020-11-12T03:17:51.665997Z",
     "shell.execute_reply.started": "2020-11-12T03:17:51.640039Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-1f1da723662b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmc_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coefficient: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-18452f5aecfb>\u001b[0m in \u001b[0;36msummary_types\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msite_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         values = values.reshape((values.shape[0], values.shape[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmarginal_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdescribe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarginal_site\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpercentiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msite_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msite_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"std\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"5%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"25%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"50%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"75%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"95%\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;31m# by definition an array here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/py3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must pass 2-d input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "for site, values in summary_types(hmc_samples).items():\n",
    "    print(\"Coefficient: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
